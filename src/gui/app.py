import threading
import time
import json
from pathlib import Path
import sys

import pandas as pd
import streamlit as st
import numpy as np

# å…¼å®¹åœ¨ä¸åŒå·¥ä½œç›®å½•ä¸‹è¿è¡Œ Streamlitï¼šç¡®ä¿é¡¹ç›®æ ¹ç›®å½•åŠ å…¥ sys.path
PROJECT_ROOT = Path(__file__).resolve().parents[2]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

# å¯¼å…¥å·²æœ‰çˆ¬è™«ï¼ˆå…¼å®¹ä¸åŒå·¥ä½œç›®å½•ï¼‰
try:
    from src.scrap import RealtimeHotScraper
except ModuleNotFoundError:
    ALT_SRC = PROJECT_ROOT / "src"
    if str(ALT_SRC) not in sys.path:
        sys.path.insert(0, str(ALT_SRC))
    from scrap import RealtimeHotScraper

# å¯¼å…¥json_analyzeræ¨¡å—
try:
    from src.json_analyzer import load_json_data, basic_analysis, setup_font, analyze_json
except ModuleNotFoundError:
    from json_analyzer import load_json_data, basic_analysis, setup_font, analyze_json

# è®¾ç½®é¡µé¢å¸ƒå±€ä¸ºå®½å±æ¨¡å¼
st.set_page_config(
    page_title="å¾®åšçƒ­æœæ•°æ®åˆ†æç³»ç»Ÿ",
    page_icon="ğŸ“Š",
    layout="wide",  # ä½¿ç”¨å®½å±å¸ƒå±€
    initial_sidebar_state="expanded",
)

# -------- é¡µé¢æ³¨å†Œä¸è·¯ç”±ï¼ˆå¯æ‰©å±•ï¼‰ -------- #
PAGES = {}


def register_page(name: str):
    def decorator(func):
        PAGES[name] = func
        return func

    return decorator


# -------- å®æ—¶çƒ­æœé¡µé¢ -------- #
@st.cache_resource
def get_realtime_scraper(timeout: int = 30, max_retries: int = 3, delay: float = 1.0):
    """ç¼“å­˜çˆ¬è™«å®ä¾‹"""
    return RealtimeHotScraper(timeout=timeout, max_retries=max_retries, delay=delay)


@st.cache_data(ttl=300)  # ç¼“å­˜5åˆ†é’Ÿ
def fetch_realtime_data(
    timeout: int = 30,
    max_retries: int = 3,
    delay: float = 1.0,
    force_refresh: bool = False,
):
    """è·å–å®æ—¶çƒ­æœæ•°æ®ï¼Œç¼“å­˜5åˆ†é’Ÿ"""
    scraper = get_realtime_scraper(timeout, max_retries, delay)
    # å¦‚æœå¼ºåˆ¶åˆ·æ–°ï¼Œä¸ä½¿ç”¨ç¼“å­˜
    return scraper.fetch_realtime_top50(use_cache=not force_refresh)


@register_page("å®æ—¶çƒ­æœ Top50")
def page_realtime_hot():
    st.title("å¾®åšå®æ—¶çƒ­æœ Top50")

    # å‚æ•°è®¾ç½®ï¼ˆä½¿ç”¨ columns æ’åˆ—ï¼‰
    col_a, col_b, col_c, col_d = st.columns(4)
    with col_a:
        timeout = st.number_input("è¯·æ±‚è¶…æ—¶(s)", min_value=5, max_value=120, value=30)
    with col_b:
        max_retries = st.number_input(
            "æœ€å¤§é‡è¯•æ¬¡æ•°", min_value=1, max_value=10, value=3
        )
    with col_c:
        delay = st.number_input(
            "é‡è¯•é—´éš”(s)", min_value=0.0, max_value=10.0, value=1.0, step=0.5
        )
    with col_d:
        refresh_btn = st.button("ğŸ”„ åˆ·æ–°æ•°æ®", help="å¼ºåˆ¶åˆ·æ–°çƒ­æœæ•°æ®ï¼ˆå¿½ç•¥ç¼“å­˜ï¼‰")

    # è‡ªåŠ¨è·å–æ•°æ®æˆ–åœ¨ç”¨æˆ·ç‚¹å‡»åˆ·æ–°æ—¶é‡æ–°è·å–
    if refresh_btn:
        # æ¸…ç©ºç¼“å­˜å¹¶é‡æ–°è·å–
        st.cache_data.clear()
        items: List[Dict[str, Any]] = fetch_realtime_data(
            timeout, max_retries, delay, force_refresh=True
        )
    else:
        # é¦–æ¬¡åŠ è½½æˆ–æ˜¾ç¤ºç¼“å­˜æ•°æ®
        placeholder = st.empty()

        # æ˜¾ç¤ºåŠ è½½æç¤º
        with placeholder.container():
            st.info("â³ æ­£åœ¨è·å–å®æ—¶çƒ­æœæ•°æ®ï¼Œè¯·ç¨å€™â€¦")

        # åå°è·å–æ•°æ®
        items = fetch_realtime_data(timeout, max_retries, delay, force_refresh=False)
        placeholder.empty()

    if not items:
        st.error("âŒ æœªè·å–åˆ°æ•°æ®ã€‚è¯·å°è¯•ä»¥ä¸‹æ“ä½œï¼š")
        st.markdown("""
        1. æ£€æŸ¥ç½‘ç»œè¿æ¥
        2. ç¨åé‡è¯•
        3. åœ¨ç»ˆç«¯è¿è¡Œï¼š`python -m playwright install chromium`
        4. æˆ–åœ¨å‘½ä»¤è¡Œè¿è¡Œï¼š`python src/scrap.py realtime` é¢„å…ˆè·å–æ•°æ®ç¼“å­˜
        """)
        st.info(
            "ğŸ“ ä½ ä¹Ÿå¯ä»¥åœ¨å·¥ä½œç›®å½•æŸ¥çœ‹ debug_realtime_page_playwright.html ä»¥æ£€æŸ¥é¡µé¢ç»“æ„ã€‚"
        )
        return

    # è·å–æ—¶é—´æˆ³
    from datetime import datetime

    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    st.success(f"âœ… æˆåŠŸè·å– {len(items)} æ¡çƒ­æœ (æ›´æ–°æ—¶é—´: {current_time})")

    # å±•ç¤ºè¡¨æ ¼
    df = pd.DataFrame(items)
    display_cols = ["rank", "title"]

    # ä½¿ç”¨HTMLè¡¨æ ¼å®ç°ç¾åŒ–
    html_table = "<table style='width:100%; border-collapse: collapse;'>"
    html_table += "<thead><tr style='background-color: #f0f0f0;'>"
    html_table += "<th style='text-align:center; padding:10px; border-bottom:2px solid #ddd; font-weight:bold;'>æ’å</th>"
    html_table += "<th style='text-align:left; padding:10px; border-bottom:2px solid #ddd; font-weight:bold;'>çƒ­æœæ ‡é¢˜</th>"
    html_table += "</tr></thead><tbody>"

    for idx, (_, row) in enumerate(df[display_cols].iterrows()):
        # äº¤æ›¿è¡Œé¢œè‰²
        bg_color = "#fafafa" if idx % 2 == 0 else "white"
        html_table += f"<tr style='background-color: {bg_color};'>"
        html_table += f"<td style='text-align:center; padding:8px; border-bottom:1px solid #eee; font-weight:bold;'>{row['rank']}</td>"
        html_table += f"<td style='text-align:left; padding:8px; border-bottom:1px solid #eee;'>{row['title']}</td>"
        html_table += "</tr>"

    html_table += "</tbody></table>"
    st.markdown(html_table, unsafe_allow_html=True)

    # åˆ†åˆ—æ˜¾ç¤ºä¸‹è½½å’Œå…¶ä»–é€‰é¡¹
    col1, col2, col3 = st.columns(3)

    with col1:
        # ä¸‹è½½ JSON
        json_bytes = json.dumps(items, ensure_ascii=False, indent=2).encode("utf-8")
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½ä¸º JSON",
            data=json_bytes,
            file_name="weibo_realtime_top50.json",
            mime="application/json",
        )

    with col2:
        # ä¸‹è½½ä¸º CSV
        csv_bytes = (
            df[display_cols].to_csv(index=False, encoding="utf-8-sig").encode("utf-8")
        )
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½ä¸º CSV",
            data=csv_bytes,
            file_name="weibo_realtime_top50.csv",
            mime="text/csv",
        )

    with col3:
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        if st.button("ğŸ“Š æ˜¾ç¤ºç»Ÿè®¡", help="æ˜¾ç¤ºæ›´å¤šç»Ÿè®¡ä¿¡æ¯"):
            st.subheader("æ•°æ®ç»Ÿè®¡")
            st.write(f"**æ€»æ¡æ•°**: {len(items)}")
            st.write(f"**æ’åèŒƒå›´**: {df['rank'].min()} - {df['rank'].max()}")


# -------- å•æ—¥æ•°æ®åˆ†æé¡µé¢ -------- #
@register_page("å•æ—¥åˆ†æ ğŸ“ˆ")
def page_daily_analysis():
    st.title("ğŸ“ˆ å•æ—¥çƒ­æœæ•°æ®åˆ†æ")
    
    # é€‰æ‹©æ—¥æœŸ
    data_processed_dir = Path("data_processed")
    
    if not data_processed_dir.exists():
        st.error("data_processed ç›®å½•ä¸å­˜åœ¨")
        return
    
    # è·å–æ‰€æœ‰å¯ç”¨çš„æ—¥æœŸ
    available_dates = []
    for year_folder in sorted(data_processed_dir.glob("202*")):
        for json_file in sorted(year_folder.glob("*.json")):
            date_str = json_file.stem
            available_dates.append((date_str, str(json_file)))
    
    if not available_dates:
        st.error("æ²¡æœ‰å¯ç”¨çš„æ•°æ®æ–‡ä»¶")
        return
    
    # é€‰æ‹©æ—¥æœŸ
    col1, col2, col3 = st.columns([2, 1, 1])
    with col1:
        selected_date, json_path = st.selectbox(
            "é€‰æ‹©åˆ†ææ—¥æœŸ",
            options=available_dates,
            format_func=lambda x: x[0]
        )
    
    with col2:
        analysis_button = st.button("ğŸ”„ ç”Ÿæˆåˆ†æ", help="è°ƒç”¨ json_analyzer ç”Ÿæˆå®Œæ•´åˆ†æå›¾è¡¨")
    
    with col3:
        if st.button("ğŸ”ƒ åˆ·æ–°", help="åˆ·æ–°é¡µé¢"):
            st.rerun()
    
    # å½“ç‚¹å‡»ç”Ÿæˆåˆ†ææŒ‰é’®æ—¶
    if analysis_button:
        with st.spinner("æ­£åœ¨ç”Ÿæˆåˆ†æ..."):
            try:
                import io
                from contextlib import redirect_stdout
                
                # æ•è· analyze_json çš„è¾“å‡º
                f = io.StringIO()
                with redirect_stdout(f):
                    analyze_json(json_path)
                
                output_log = f.getvalue()
                st.success("âœ… åˆ†æå®Œæˆï¼")
                
                # æ˜¾ç¤ºè¾“å‡ºæ—¥å¿—
                with st.expander("ğŸ“‹ åˆ†ææ—¥å¿—"):
                    st.code(output_log, language="text")
                
            except Exception as e:
                st.error(f"åˆ†æå¤±è´¥: {str(e)}")
                import traceback
                st.error(traceback.format_exc())
                return
    
    # æ˜¾ç¤ºç”Ÿæˆçš„åˆ†æç»“æœ
    from datetime import datetime
    
    # æ„é€ è¾“å‡ºç›®å½•è·¯å¾„
    date_obj = datetime.strptime(selected_date, "%Y-%m-%d")
    output_dir = Path("output") / selected_date
    
    if not output_dir.exists():
        st.info("ğŸ‘‰ è¯·å…ˆç‚¹å‡» 'ğŸ”„ ç”Ÿæˆåˆ†æ' æŒ‰é’®æ¥ç”Ÿæˆåˆ†æç»“æœ")
        return
    
    # æŸ¥æ‰¾æ‰€æœ‰ç”Ÿæˆçš„ PNG å›¾è¡¨
    chart_files = sorted(output_dir.glob("*.png"))
    
    if not chart_files:
        st.warning("æ²¡æœ‰ç”Ÿæˆçš„å›¾è¡¨")
        return
    
    # åˆ›å»ºé€‰é¡¹å¡æ˜¾ç¤ºå„ä¸ªå›¾è¡¨
    st.markdown("### ğŸ“Š åˆ†æå›¾è¡¨")
    
    # ä¸ºæ¯ä¸ªå›¾è¡¨åˆ›å»ºé€‰é¡¹å¡
    if len(chart_files) > 0:
        tabs = st.tabs([f.stem.replace(f"{selected_date}_", "").replace("_", " ") for f in chart_files])
        
        for tab, chart_file in zip(tabs, chart_files):
            with tab:
                # ç›´æ¥ä½¿ç”¨æ–‡ä»¶è·¯å¾„æ˜¾ç¤ºå›¾ç‰‡ï¼Œé¿å…å­—èŠ‚æµè§£ç é—®é¢˜
                st.image(str(chart_file), use_column_width=True, caption=chart_file.name)

                # æä¾›ä¸‹è½½æŒ‰é’®ï¼ˆè¯»å–å­—èŠ‚ä¾›ä¸‹è½½ï¼‰
                try:
                    with open(chart_file, "rb") as f:
                        image_data = f.read()
                    st.download_button(
                        f"ğŸ“¥ ä¸‹è½½ {chart_file.name}",
                        data=image_data,
                        file_name=chart_file.name,
                        mime="image/png"
                    )
                except Exception as e:
                    st.warning(f"æ— æ³•æä¾›ä¸‹è½½ï¼š{e}")
    
    # æ˜¾ç¤ºåˆ†ææŠ¥å‘Š
    report_file = output_dir / "analysis_report.txt"
    if report_file.exists():
        st.markdown("### ğŸ“„ åˆ†ææŠ¥å‘Š")
        with open(report_file, "r", encoding="utf-8") as f:
            report_content = f.read()
        
        with st.expander("å±•å¼€æŸ¥çœ‹å®Œæ•´æŠ¥å‘Š"):
            st.text(report_content)
        
        # æä¾›æŠ¥å‘Šä¸‹è½½
        st.download_button(
            "ğŸ“¥ ä¸‹è½½åˆ†ææŠ¥å‘Š",
            data=report_content.encode("utf-8"),
            file_name=f"{selected_date}_analysis_report.txt",
            mime="text/plain"
        )


# -------- å…³é”®è¯å…±ç°ç½‘ç»œé¡µé¢ -------- #
@register_page("å…³é”®è¯ç½‘ç»œ ğŸŒ")
def page_keyword_network():
    st.title("ğŸŒ å…³é”®è¯å…±ç°ç½‘ç»œåˆ†æ")
    
    network_data_dir = Path("output/word_networks/data")
    
    if not network_data_dir.exists():
        st.error("ç½‘ç»œæ•°æ®ç›®å½•ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ word_network.py")
        return
    
    # è·å–å¯ç”¨çš„ç½‘ç»œæ•°æ®
    available_networks = []
    for json_file in sorted(network_data_dir.glob("nodes_*.json")):
        year = json_file.stem.replace("nodes_", "")
        available_networks.append(year)
    
    if not available_networks:
        st.error("æ²¡æœ‰å¯ç”¨çš„ç½‘ç»œæ•°æ®")
        return
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        selected_year = st.selectbox(
            "é€‰æ‹©å¹´ä»½",
            options=available_networks,
            format_func=lambda x: f"{x} å¹´"
        )
    
    with col2:
        if st.button("ğŸ”„ åˆ·æ–°", help="é‡æ–°åŠ è½½æ•°æ®"):
            st.rerun()
    
    # åŠ è½½èŠ‚ç‚¹å’Œè¾¹æ•°æ®
    try:
        with open(network_data_dir / f"nodes_{selected_year}.json", 'r', encoding='utf-8') as f:
            nodes_data = json.load(f)
        
        with open(network_data_dir / f"edges_{selected_year}.json", 'r', encoding='utf-8') as f:
            edges_data = json.load(f)
    except Exception as e:
        st.error(f"åŠ è½½å¤±è´¥: {e}")
        return
    
    # ========== TAB è§†å›¾ ==========
    tab1, tab2, tab3 = st.tabs(["ğŸ–¼ï¸ ç½‘ç»œå›¾", "ğŸ“Š ç»Ÿè®¡", "ğŸ“‹ æ•°æ®è¡¨"])
    
    with tab1:
        st.subheader("å…³é”®è¯å…±ç°ç½‘ç»œå¯è§†åŒ–")
        
        # æ˜¾ç¤ºç½‘ç»œå›¾
        network_img_path = Path("output/word_networks/figures") / f"keyword_network_{selected_year}.png"
        if network_img_path.exists():
            st.image(str(network_img_path), use_column_width=True)
            
            with open(network_img_path, 'rb') as f:
                st.download_button("ğŸ“¥ ä¸‹è½½ç½‘ç»œå›¾", f.read(), f"keyword_network_{selected_year}.png", "image/png")
        else:
            st.warning("ç½‘ç»œå›¾æ–‡ä»¶ä¸å­˜åœ¨")
    
    with tab2:
        st.subheader("ç½‘ç»œç»Ÿè®¡")
        
        nodes_count = len(nodes_data)
        edges_count = len(edges_data)
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("èŠ‚ç‚¹æ•°ï¼ˆå…³é”®è¯ï¼‰", nodes_count)
        
        with col2:
            st.metric("è¾¹æ•°ï¼ˆå…±ç°å…³ç³»ï¼‰", edges_count)
        
        with col3:
            if edges_count > 0:
                avg_cooccur = np.mean([e['weight'] for e in edges_data])
                st.metric("å¹³å‡å…±ç°åº¦", f"{avg_cooccur:.2f}")
            else:
                st.metric("å¹³å‡å…±ç°åº¦", "0")
        
        with col4:
            if nodes_count > 0:
                avg_freq = np.mean([n['frequency'] for n in nodes_data])
                st.metric("å¹³å‡å…³é”®è¯é¢‘æ¬¡", f"{avg_freq:.2f}")
            else:
                st.metric("å¹³å‡å…³é”®è¯é¢‘æ¬¡", "0")
        
        # é¢‘æ¬¡TOP 10
        import plotly.express as px
        top_nodes = sorted(nodes_data, key=lambda x: x['frequency'], reverse=True)[:10]
        
        fig = px.bar(
            x=[n['frequency'] for n in top_nodes],
            y=[n['keyword'] for n in top_nodes],
            orientation='h',
            title="å…³é”®è¯é¢‘æ¬¡ Top 10",
            color=[n['frequency'] for n in top_nodes],
            color_continuous_scale="Viridis"
        )
        fig.update_yaxes(automargin=True)
        st.plotly_chart(fig, use_container_width=True)
        
        # å…±ç°åº¦æœ€é«˜çš„å…³ç³»
        top_edges = sorted(edges_data, key=lambda x: x['weight'], reverse=True)[:10]
        
        edge_labels = [f"{e['source']} - {e['target']}" for e in top_edges]
        edge_weights = [e['weight'] for e in top_edges]
        
        fig = px.bar(
            x=edge_weights,
            y=edge_labels,
            orientation='h',
            title="å…±ç°å…³ç³» Top 10",
            color=edge_weights,
            color_continuous_scale="Reds"
        )
        fig.update_yaxes(automargin=True)
        st.plotly_chart(fig, use_container_width=True)
    
    with tab3:
        st.subheader("èŠ‚ç‚¹å’Œè¾¹æ•°æ®")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### å…³é”®è¯èŠ‚ç‚¹")
            nodes_df = pd.DataFrame(nodes_data).sort_values('frequency', ascending=False)
            st.dataframe(nodes_df, use_container_width=True, height=400)
            
            csv = nodes_df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8')
            st.download_button("ğŸ“¥ ä¸‹è½½èŠ‚ç‚¹æ•°æ®", csv, f"nodes_{selected_year}.csv", "text/csv")
        
        with col2:
            st.markdown("#### å…±ç°å…³ç³»")
            edges_df = pd.DataFrame(edges_data).sort_values('weight', ascending=False)
            st.dataframe(edges_df, use_container_width=True, height=400)
            
            csv = edges_df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8')
            st.download_button("ğŸ“¥ ä¸‹è½½è¾¹æ•°æ®", csv, f"edges_{selected_year}.csv", "text/csv")


# -------- å†å²æ•°æ®å¯è§†åŒ–é¡µé¢ -------- #
@register_page("å†å²æ•°æ®å¯è§†åŒ–")
def page_history_visualization():
    st.title("å†å²æ•°æ®å¯è§†åŒ–")

    import os
    from pathlib import Path

    # è·å–è¯äº‘å›¾ç›®å½•
    word_clouds_dir = Path("output/word_clouds")

    if not word_clouds_dir.exists():
        st.error("è¯äº‘å›¾ç›®å½•ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œæ•°æ®å¤„ç†ç”Ÿæˆè¯äº‘å›¾")
        return

    # å±…ä¸­æ˜¾ç¤ºé€‰é¡¹
    st.markdown("### ğŸ“Š è¯äº‘å›¾æŸ¥çœ‹å™¨")

    # åˆ›å»ºå±…ä¸­çš„é€‰é¡¹åŒºåŸŸ
    col1, col2, col3, col4, col5 = st.columns([1, 2, 2, 2, 1])

    with col2:
        # é€‰æ‹©ç±»å‹ï¼šå…³é”®è¯æˆ–ç±»å‹
        viz_type = st.selectbox(
            "é€‰æ‹©åˆ†æç»´åº¦",
            options=["å…³é”®è¯", "ç±»å‹"],
            help="å…³é”®è¯ï¼šåŸºäºçƒ­æœæ ‡é¢˜çš„è¯é¢‘åˆ†æ\nç±»å‹ï¼šåŸºäºçƒ­æœåˆ†ç±»çš„ç»Ÿè®¡",
        )

    with col3:
        # è·å–å¯ç”¨çš„æœˆä»½é€‰é¡¹
        type_folder = "keywords" if viz_type == "å…³é”®è¯" else "types"
        folder_path = word_clouds_dir / type_folder

        # æ‰«æå¯ç”¨çš„å›¾ç‰‡æ–‡ä»¶
        available_files = []
        if folder_path.exists():
            available_files = sorted(
                [
                    f.stem
                    for f in folder_path.glob("*.png")
                    if not f.name.startswith("custom_analysis")
                ]
            )

        if not available_files:
            st.warning(f"æœªæ‰¾åˆ°{viz_type}è¯äº‘å›¾")
            return

        # æ„å»ºæœˆä»½é€‰é¡¹
        month_options = []
        month_display = {}

        for filename in available_files:
            if filename.endswith("2025"):
                display_name = "å…¨å¹´æ±‡æ€» (2025)"
                month_options.append(filename)
                month_display[filename] = display_name
            elif "Q" in filename:
                quarter = filename.split("-")[-1]
                display_name = f"å­£åº¦æ±‡æ€» ({quarter})"
                month_options.append(filename)
                month_display[filename] = display_name
            elif "-" in filename:
                parts = filename.split("_")[-1].split("-")
                if len(parts) == 2:
                    year, month = parts
                    display_name = f"{year}å¹´{month}æœˆ"
                    month_options.append(filename)
                    month_display[filename] = display_name

        # é€‰æ‹©æœˆä»½
        selected_file = st.selectbox(
            "é€‰æ‹©æ—¶é—´èŒƒå›´",
            options=month_options,
            format_func=lambda x: month_display.get(x, x),
            help="é€‰æ‹©è¦æŸ¥çœ‹çš„æœˆä»½æˆ–æ±‡æ€»æœŸé—´",
        )

    with col4:
        # æ·»åŠ åˆ·æ–°æŒ‰é’®
        if st.button("ğŸ”„ åˆ·æ–°", help="é‡æ–°åŠ è½½è¯äº‘å›¾"):
            st.rerun()

    # æ˜¾ç¤ºè¯äº‘å›¾
    if selected_file:
        image_path = folder_path / f"{selected_file}.png"

        if image_path.exists():
            # å±…ä¸­æ˜¾ç¤ºè¯äº‘å›¾
            col_left, col_center, col_right = st.columns([0.5, 3, 0.5])
            with col_center:
                st.image(str(image_path), use_column_width=True)

            # æ˜¾ç¤ºä¸‹è½½æŒ‰é’®
            with open(image_path, "rb") as f:
                image_bytes = f.read()

            st.download_button(
                label="ğŸ“¥ ä¸‹è½½è¯äº‘å›¾",
                data=image_bytes,
                file_name=f"{selected_file}.png",
                mime="image/png",
            )

            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            with st.expander("ğŸ“Š æŸ¥çœ‹å…¶ä»–æ—¶é—´èŒƒå›´", expanded=False):
                # æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨çš„æ—¶é—´èŒƒå›´
                st.markdown("#### å¯ç”¨çš„è¯äº‘å›¾ï¼š")
                cols = st.columns(4)
                for idx, file in enumerate(month_options):
                    with cols[idx % 4]:
                        if file == selected_file:
                            st.markdown(f"**âœ“ {month_display[file]}**")
                        else:
                            st.markdown(f"- {month_display[file]}")
        else:
            st.error(f"è¯äº‘å›¾æ–‡ä»¶ä¸å­˜åœ¨ï¼š{image_path}")
    else:
        st.warning("è¯·é€‰æ‹©è¦æŸ¥çœ‹çš„æ—¶é—´èŒƒå›´")


@register_page("æ•°æ®å¤„ç†å·¥å…·")
def page_tools_placeholder():
    st.title("æ•°æ®å¤„ç†å·¥å…·ï¼ˆå ä½ï¼‰")
    st.info("åç»­å¯æ·»åŠ æ¸…æ´—ã€è½¬æ¢ä¸å¯¼å‡ºå·¥å…·ã€‚")


@register_page("JSONæ•°æ®åˆ†æ")
def page_json_analysis():
    st.title("JSONæ•°æ®åˆ†æå·¥å…·")
    st.markdown("""
    æœ¬å·¥å…·ç”¨äºåˆ†æå¾®åšçƒ­æœJSONæ•°æ®ï¼Œç”Ÿæˆç»Ÿè®¡å›¾è¡¨å’Œå¯è§†åŒ–æŠ¥å‘Šã€‚

    **æ”¯æŒçš„æ•°æ®æ ¼å¼ï¼š**
    - åŸå§‹æ•°æ®æ ¼å¼ï¼ˆåŒ…å« `date`, `count`, `data` å­—æ®µï¼‰
    - æŸ¥è¯¢ç»“æœæ ¼å¼ï¼ˆåŒ…å« `query_time`, `result_count`, `results` å­—æ®µï¼‰
    - æ•°æ®åˆ—è¡¨æ ¼å¼
    """)

    # æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
    st.markdown("### 1. é€‰æ‹©æ•°æ®æ–‡ä»¶")
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ JSONæ–‡ä»¶", type=["json"], help="é€‰æ‹©è¦åˆ†æçš„JSONæ•°æ®æ–‡ä»¶"
    )

    # æˆ–è€…è¾“å…¥æ–‡ä»¶è·¯å¾„
    col1, col2 = st.columns(2)
    with col1:
        file_path = st.text_input(
            "æˆ–è¾“å…¥æ–‡ä»¶è·¯å¾„",
            placeholder="ä¾‹å¦‚ï¼šdata/2025-01/2025-01-01.json",
            help="ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„è·¯å¾„",
        )

    with col2:
        font_name = st.text_input(
            "å›¾è¡¨å­—ä½“", value="Maple Mono NF CN", help="ç”¨äºå›¾è¡¨æ˜¾ç¤ºçš„å­—ä½“åç§°"
        )

    # åˆ†æé€‰é¡¹
    st.markdown("### 2. åˆ†æé€‰é¡¹")
    col3, col4, col5 = st.columns(3)
    with col3:
        generate_charts = st.checkbox("ç”Ÿæˆå›¾è¡¨", value=True)
    with col4:
        generate_report = st.checkbox("ç”Ÿæˆåˆ†ææŠ¥å‘Š", value=True)
    with col5:
        high_resolution = st.checkbox("é«˜åˆ†è¾¨ç‡å›¾è¡¨", value=True)

    # æ‰§è¡Œåˆ†ææŒ‰é’®
    st.markdown("### 3. æ‰§è¡Œåˆ†æ")
    analyze_button = st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary", use_container_width=True)

    if analyze_button:
        # ç¡®å®šè¦åˆ†æçš„æ–‡ä»¶
        json_file = None
        if uploaded_file is not None:
            # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
            import os
            import tempfile

            with tempfile.NamedTemporaryFile(delete=False, suffix=".json") as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                json_file = tmp_file.name
                st.info(f"å·²ä¸Šä¼ æ–‡ä»¶: {uploaded_file.name}")
        elif file_path and os.path.exists(file_path):
            json_file = file_path
            st.info(f"ä½¿ç”¨æ–‡ä»¶: {file_path}")
        else:
            st.error("è¯·ä¸Šä¼ æ–‡ä»¶æˆ–è¾“å…¥æœ‰æ•ˆçš„æ–‡ä»¶è·¯å¾„")
            return

        if json_file:
            try:
                # è®¾ç½®å­—ä½“
                from src.json_analyzer import setup_font

                setup_font(font_name)

                # æ‰§è¡Œåˆ†æ
                with st.spinner("æ­£åœ¨åˆ†ææ•°æ®ï¼Œè¯·ç¨å€™..."):
                    from src.json_analyzer import analyze_json

                    # è°ƒç”¨åˆ†æå‡½æ•°
                    analyze_json(json_file)

                st.success("âœ… åˆ†æå®Œæˆï¼")

                # æ˜¾ç¤ºè¾“å‡ºä¿¡æ¯
                st.markdown("### 4. åˆ†æç»“æœ")

                # è·å–è¾“å‡ºç›®å½•ï¼ˆåŸºäºæ–‡ä»¶åï¼‰
                import datetime
                from pathlib import Path

                file_name = Path(json_file).stem
                output_dir = Path("output") / f"{file_name}"

                if output_dir.exists():
                    st.info(f"åˆ†æç»“æœå·²ä¿å­˜åˆ°: `{output_dir}`")

                    # åˆ—å‡ºç”Ÿæˆçš„å›¾è¡¨æ–‡ä»¶
                    png_files = list(output_dir.glob("*.png"))
                    if png_files:
                        st.markdown("**ç”Ÿæˆçš„å›¾è¡¨ï¼š**")
                        cols = st.columns(3)
                        for idx, png_file in enumerate(png_files[:6]):  # æœ€å¤šæ˜¾ç¤º6ä¸ª
                            with cols[idx % 3]:
                                st.image(
                                    str(png_file),
                                    caption=png_file.name,
                                    use_column_width=True,
                                )

                        if len(png_files) > 6:
                            st.info(f"è¿˜æœ‰ {len(png_files) - 6} ä¸ªå›¾è¡¨æœªæ˜¾ç¤º")

                    # æ£€æŸ¥åˆ†ææŠ¥å‘Š
                    report_file = output_dir / "analysis_report.txt"
                    if report_file.exists():
                        with open(report_file, "r", encoding="utf-8") as f:
                            report_content = f.read()

                        with st.expander("ğŸ“„ æŸ¥çœ‹åˆ†ææŠ¥å‘Š", expanded=False):
                            st.text(report_content)

                        # ä¸‹è½½æŒ‰é’®
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½åˆ†ææŠ¥å‘Š",
                            data=report_content,
                            file_name="analysis_report.txt",
                            mime="text/plain",
                        )

                    # æä¾›ä¸‹è½½æ‰€æœ‰ç»“æœçš„é€‰é¡¹
                    st.markdown("**ä¸‹è½½æ‰€æœ‰ç»“æœï¼š**")

                    # åˆ›å»ºZIPæ–‡ä»¶
                    import io
                    import zipfile

                    zip_buffer = io.BytesIO()
                    with zipfile.ZipFile(
                        zip_buffer, "w", zipfile.ZIP_DEFLATED
                    ) as zip_file:
                        for file_path in output_dir.glob("*"):
                            if file_path.is_file():
                                zip_file.write(file_path, file_path.name)

                    zip_buffer.seek(0)

                    st.download_button(
                        label="ğŸ“¦ ä¸‹è½½æ‰€æœ‰å›¾è¡¨å’ŒæŠ¥å‘Š (ZIP)",
                        data=zip_buffer,
                        file_name=f"analysis_results_{file_name}.zip",
                        mime="application/zip",
                    )

                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if uploaded_file is not None:
                    import os

                    os.unlink(json_file)

            except Exception as e:
                st.error(f"åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
                import traceback

                with st.expander("æŸ¥çœ‹é”™è¯¯è¯¦æƒ…"):
                    st.code(traceback.format_exc())

    # ç¤ºä¾‹æ•°æ®
    with st.expander("ğŸ“‹ æŸ¥çœ‹ç¤ºä¾‹JSONæ ¼å¼", expanded=False):
        st.code(
            """{
    "date": "2025-01-01",
    "count": 50,
    "data": [
        {
            "rank": 1,
            "title": "ç¤ºä¾‹çƒ­æœæ ‡é¢˜",
            "category": "æ˜æ˜Ÿ",
            "heat": 1234567.8,
            "reads": 9876543,
            "discussions": 12345,
            "originals": 6789
        }
        // ... æ›´å¤šæ•°æ®
    ]
}""",
            language="json",
        )


# -------- ä¸»å…¥å£ -------- #
def main():
    st.sidebar.title("åŠŸèƒ½å¯¼èˆª")
    page_name = st.sidebar.selectbox("é€‰æ‹©é¡µé¢", options=list(PAGES.keys()))

    # æ·»åŠ ä¾§è¾¹æ ä¿¡æ¯
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ“Š é¡¹ç›®ä¿¡æ¯")
    st.sidebar.info("**å¾®åšçƒ­æœæ•°æ®åˆ†æç³»ç»Ÿ**\n\nå®æ—¶è·å–å’Œåˆ†æå¾®åšçƒ­æœè¶‹åŠ¿")

    st.sidebar.markdown("### ğŸ“– ä½¿ç”¨è¯´æ˜")
    with st.sidebar.expander("å®æ—¶çƒ­æœ", expanded=False):
        st.markdown("""
        - è·å–å¾®åšå®æ—¶ Top 50 çƒ­æœ
        - æ”¯æŒç¼“å­˜åŠ é€Ÿ
        - å¯ä¸‹è½½ JSON æ•°æ®
        """)
    
    with st.sidebar.expander("å•æ—¥åˆ†æ", expanded=False):
        st.markdown("""
        - é€‰æ‹©æ—¥æœŸåˆ†æå•æ—¥æ•°æ®
        - è°ƒç”¨ json_analyzer æ¨¡å—
        - æ”¯æŒæ•°æ®å¯¼å‡º
        """)
    
    with st.sidebar.expander("å…³é”®è¯ç½‘ç»œ", expanded=False):
        st.markdown("""
        - æŸ¥çœ‹å…³é”®è¯å…±ç°ç½‘ç»œ
        - èŠ‚ç‚¹å’Œè¾¹çš„ç»Ÿè®¡æ•°æ®
        - å¯¼å‡ºæ•°æ®ä¸º CSV
        """)
    
    with st.sidebar.expander("å†å²æ•°æ®å¯è§†åŒ–", expanded=False):
        st.markdown("""
        - æŸ¥çœ‹å†å²è¯äº‘å›¾
        - æŒ‰å…³é”®è¯/ç±»å‹åˆ†æ
        - æ”¯æŒæœˆåº¦/å­£åº¦/å¹´åº¦
        """)

    with st.sidebar.expander("æ•°æ®å¤„ç†", expanded=False):
        st.markdown("""
        - æ•°æ®æ¸…æ´—ä¸è½¬æ¢
        - æ‰¹é‡å¯¼å‡ºå·¥å…·
        - è‡ªå®šä¹‰åˆ†æ
        """)

    st.sidebar.markdown("---")
    st.sidebar.markdown("### âš™ï¸ ç³»ç»ŸçŠ¶æ€")
    import os
    from pathlib import Path

    # ç»Ÿè®¡æ•°æ®
    data_dir = Path("data")
    output_dir = Path("output/word_clouds")
    network_dir = Path("output/word_networks")
    
    if data_dir.exists():
        json_files = list(data_dir.glob("**/*.json"))
        st.sidebar.success(f"âœ“ å·²å­˜å‚¨ {len(json_files)} ä¸ªæ•°æ®æ–‡ä»¶")
    else:
        st.sidebar.warning("âš  æ•°æ®ç›®å½•ä¸å­˜åœ¨")

    if output_dir.exists():
        img_files = list(output_dir.glob("**/*.png"))
        st.sidebar.success(f"âœ“ å·²ç”Ÿæˆ {len(img_files)} å¼ è¯äº‘å›¾")
    else:
        st.sidebar.warning("âš  è¯äº‘å›¾ç›®å½•ä¸å­˜åœ¨")
    
    if network_dir.exists():
        network_files = list(network_dir.glob("**/*.json"))
        st.sidebar.success(f"âœ“ å·²ç”Ÿæˆ {len(network_files) // 2} ä¸ªç½‘ç»œå›¾")
    else:
        st.sidebar.warning("âš  ç½‘ç»œå›¾ç›®å½•ä¸å­˜åœ¨")
    
    PAGES[page_name]()


if __name__ == "__main__":
    main()
