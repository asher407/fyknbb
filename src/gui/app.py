import threading
import time
from typing import Any, Dict, List

import pandas as pd
import streamlit as st

# å¯¼å…¥å·²æœ‰çˆ¬è™«
from src.scrap import RealtimeHotScraper

# è®¾ç½®é¡µé¢å¸ƒå±€ä¸ºå®½å±æ¨¡å¼
st.set_page_config(
    page_title="å¾®åšçƒ­æœæ•°æ®åˆ†æç³»ç»Ÿ",
    page_icon="ğŸ“Š",
    layout="wide",  # ä½¿ç”¨å®½å±å¸ƒå±€
    initial_sidebar_state="expanded",
)

# -------- é¡µé¢æ³¨å†Œä¸è·¯ç”±ï¼ˆå¯æ‰©å±•ï¼‰ -------- #
PAGES = {}


def register_page(name: str):
    def decorator(func):
        PAGES[name] = func
        return func

    return decorator


# -------- å®æ—¶çƒ­æœé¡µé¢ -------- #
@st.cache_resource
def get_realtime_scraper(timeout: int = 30, max_retries: int = 3, delay: float = 1.0):
    """ç¼“å­˜çˆ¬è™«å®ä¾‹"""
    return RealtimeHotScraper(timeout=timeout, max_retries=max_retries, delay=delay)


@st.cache_data(ttl=300)  # ç¼“å­˜5åˆ†é’Ÿ
def fetch_realtime_data(
    timeout: int = 30,
    max_retries: int = 3,
    delay: float = 1.0,
    force_refresh: bool = False,
):
    """è·å–å®æ—¶çƒ­æœæ•°æ®ï¼Œç¼“å­˜5åˆ†é’Ÿ"""
    scraper = get_realtime_scraper(timeout, max_retries, delay)
    # å¦‚æœå¼ºåˆ¶åˆ·æ–°ï¼Œä¸ä½¿ç”¨ç¼“å­˜
    return scraper.fetch_realtime_top50(use_cache=not force_refresh)


@register_page("å®æ—¶çƒ­æœ Top50")
def page_realtime_hot():
    st.title("å¾®åšå®æ—¶çƒ­æœ Top50")

    # å‚æ•°è®¾ç½®ï¼ˆä½¿ç”¨ columns æ’åˆ—ï¼‰
    col_a, col_b, col_c, col_d = st.columns(4)
    with col_a:
        timeout = st.number_input("è¯·æ±‚è¶…æ—¶(s)", min_value=5, max_value=120, value=30)
    with col_b:
        max_retries = st.number_input(
            "æœ€å¤§é‡è¯•æ¬¡æ•°", min_value=1, max_value=10, value=3
        )
    with col_c:
        delay = st.number_input(
            "é‡è¯•é—´éš”(s)", min_value=0.0, max_value=10.0, value=1.0, step=0.5
        )
    with col_d:
        refresh_btn = st.button("ğŸ”„ åˆ·æ–°æ•°æ®", help="å¼ºåˆ¶åˆ·æ–°çƒ­æœæ•°æ®ï¼ˆå¿½ç•¥ç¼“å­˜ï¼‰")

    # è‡ªåŠ¨è·å–æ•°æ®æˆ–åœ¨ç”¨æˆ·ç‚¹å‡»åˆ·æ–°æ—¶é‡æ–°è·å–
    if refresh_btn:
        # æ¸…ç©ºç¼“å­˜å¹¶é‡æ–°è·å–
        st.cache_data.clear()
        items: List[Dict[str, Any]] = fetch_realtime_data(
            timeout, max_retries, delay, force_refresh=True
        )
    else:
        # é¦–æ¬¡åŠ è½½æˆ–æ˜¾ç¤ºç¼“å­˜æ•°æ®
        placeholder = st.empty()

        # æ˜¾ç¤ºåŠ è½½æç¤º
        with placeholder.container():
            st.info("â³ æ­£åœ¨è·å–å®æ—¶çƒ­æœæ•°æ®ï¼Œè¯·ç¨å€™â€¦")

        # åå°è·å–æ•°æ®
        items = fetch_realtime_data(timeout, max_retries, delay, force_refresh=False)
        placeholder.empty()

    if not items:
        st.error("âŒ æœªè·å–åˆ°æ•°æ®ã€‚è¯·å°è¯•ä»¥ä¸‹æ“ä½œï¼š")
        st.markdown("""
        1. æ£€æŸ¥ç½‘ç»œè¿æ¥
        2. ç¨åé‡è¯•
        3. åœ¨ç»ˆç«¯è¿è¡Œï¼š`python -m playwright install chromium`
        4. æˆ–åœ¨å‘½ä»¤è¡Œè¿è¡Œï¼š`python src/scrap.py realtime` é¢„å…ˆè·å–æ•°æ®ç¼“å­˜
        """)
        st.info(
            "ğŸ“ ä½ ä¹Ÿå¯ä»¥åœ¨å·¥ä½œç›®å½•æŸ¥çœ‹ debug_realtime_page_playwright.html ä»¥æ£€æŸ¥é¡µé¢ç»“æ„ã€‚"
        )
        return

    # è·å–æ—¶é—´æˆ³
    from datetime import datetime

    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    st.success(f"âœ… æˆåŠŸè·å– {len(items)} æ¡çƒ­æœ (æ›´æ–°æ—¶é—´: {current_time})")

    # å±•ç¤ºè¡¨æ ¼
    df = pd.DataFrame(items)
    display_cols = ["rank", "title"]

    # ä½¿ç”¨HTMLè¡¨æ ¼å®ç°ç¾åŒ–
    html_table = "<table style='width:100%; border-collapse: collapse;'>"
    html_table += "<thead><tr style='background-color: #f0f0f0;'>"
    html_table += "<th style='text-align:center; padding:10px; border-bottom:2px solid #ddd; font-weight:bold;'>æ’å</th>"
    html_table += "<th style='text-align:left; padding:10px; border-bottom:2px solid #ddd; font-weight:bold;'>çƒ­æœæ ‡é¢˜</th>"
    html_table += "</tr></thead><tbody>"

    for idx, (_, row) in enumerate(df[display_cols].iterrows()):
        # äº¤æ›¿è¡Œé¢œè‰²
        bg_color = "#fafafa" if idx % 2 == 0 else "white"
        html_table += f"<tr style='background-color: {bg_color};'>"
        html_table += f"<td style='text-align:center; padding:8px; border-bottom:1px solid #eee; font-weight:bold;'>{row['rank']}</td>"
        html_table += f"<td style='text-align:left; padding:8px; border-bottom:1px solid #eee;'>{row['title']}</td>"
        html_table += "</tr>"

    html_table += "</tbody></table>"
    st.markdown(html_table, unsafe_allow_html=True)

    # åˆ†åˆ—æ˜¾ç¤ºä¸‹è½½å’Œå…¶ä»–é€‰é¡¹
    col1, col2, col3 = st.columns(3)

    with col1:
        # ä¸‹è½½ JSON
        import json

        json_bytes = json.dumps(items, ensure_ascii=False, indent=2).encode("utf-8")
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½ä¸º JSON",
            data=json_bytes,
            file_name="weibo_realtime_top50.json",
            mime="application/json",
        )

    with col2:
        # ä¸‹è½½ä¸º CSV
        csv_bytes = (
            df[display_cols].to_csv(index=False, encoding="utf-8-sig").encode("utf-8")
        )
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½ä¸º CSV",
            data=csv_bytes,
            file_name="weibo_realtime_top50.csv",
            mime="text/csv",
        )

    with col3:
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        if st.button("ğŸ“Š æ˜¾ç¤ºç»Ÿè®¡", help="æ˜¾ç¤ºæ›´å¤šç»Ÿè®¡ä¿¡æ¯"):
            st.subheader("æ•°æ®ç»Ÿè®¡")
            st.write(f"**æ€»æ¡æ•°**: {len(items)}")
            st.write(f"**æ’åèŒƒå›´**: {df['rank'].min()} - {df['rank'].max()}")


# -------- å…¶ä»–é¡µé¢å ä½ï¼ˆä¾¿äºæ‰©å±•ï¼‰ -------- #
@register_page("å†å²æ•°æ®å¯è§†åŒ–")
def page_history_visualization():
    st.title("å†å²æ•°æ®å¯è§†åŒ–")

    import os
    from pathlib import Path

    # è·å–è¯äº‘å›¾ç›®å½•
    word_clouds_dir = Path("output/word_clouds")

    if not word_clouds_dir.exists():
        st.error("è¯äº‘å›¾ç›®å½•ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œæ•°æ®å¤„ç†ç”Ÿæˆè¯äº‘å›¾")
        return

    # å±…ä¸­æ˜¾ç¤ºé€‰é¡¹
    st.markdown("### ğŸ“Š è¯äº‘å›¾æŸ¥çœ‹å™¨")

    # åˆ›å»ºå±…ä¸­çš„é€‰é¡¹åŒºåŸŸ
    col1, col2, col3, col4, col5 = st.columns([1, 2, 2, 2, 1])

    with col2:
        # é€‰æ‹©ç±»å‹ï¼šå…³é”®è¯æˆ–ç±»å‹
        viz_type = st.selectbox(
            "é€‰æ‹©åˆ†æç»´åº¦",
            options=["å…³é”®è¯", "ç±»å‹"],
            help="å…³é”®è¯ï¼šåŸºäºçƒ­æœæ ‡é¢˜çš„è¯é¢‘åˆ†æ\nç±»å‹ï¼šåŸºäºçƒ­æœåˆ†ç±»çš„ç»Ÿè®¡",
        )

    with col3:
        # è·å–å¯ç”¨çš„æœˆä»½é€‰é¡¹
        type_folder = "keywords" if viz_type == "å…³é”®è¯" else "types"
        folder_path = word_clouds_dir / type_folder

        # æ‰«æå¯ç”¨çš„å›¾ç‰‡æ–‡ä»¶
        available_files = []
        if folder_path.exists():
            available_files = sorted(
                [
                    f.stem
                    for f in folder_path.glob("*.png")
                    if not f.name.startswith("custom_analysis")
                ]
            )

        if not available_files:
            st.warning(f"æœªæ‰¾åˆ°{viz_type}è¯äº‘å›¾")
            return

        # æ„å»ºæœˆä»½é€‰é¡¹
        month_options = []
        month_display = {}

        for filename in available_files:
            if filename.endswith("2025"):
                display_name = "å…¨å¹´æ±‡æ€» (2025)"
                month_options.append(filename)
                month_display[filename] = display_name
            elif "Q" in filename:
                quarter = filename.split("-")[-1]
                display_name = f"å­£åº¦æ±‡æ€» ({quarter})"
                month_options.append(filename)
                month_display[filename] = display_name
            elif "-" in filename:
                parts = filename.split("_")[-1].split("-")
                if len(parts) == 2:
                    year, month = parts
                    display_name = f"{year}å¹´{month}æœˆ"
                    month_options.append(filename)
                    month_display[filename] = display_name

        # é€‰æ‹©æœˆä»½
        selected_file = st.selectbox(
            "é€‰æ‹©æ—¶é—´èŒƒå›´",
            options=month_options,
            format_func=lambda x: month_display.get(x, x),
            help="é€‰æ‹©è¦æŸ¥çœ‹çš„æœˆä»½æˆ–æ±‡æ€»æœŸé—´",
        )

    with col4:
        # æ·»åŠ åˆ·æ–°æŒ‰é’®
        if st.button("ğŸ”„ åˆ·æ–°", help="é‡æ–°åŠ è½½è¯äº‘å›¾"):
            st.rerun()

    # æ˜¾ç¤ºè¯äº‘å›¾
    if selected_file:
        image_path = folder_path / f"{selected_file}.png"

        if image_path.exists():
            # å±…ä¸­æ˜¾ç¤ºè¯äº‘å›¾
            col_left, col_center, col_right = st.columns([0.5, 3, 0.5])
            with col_center:
                st.image(str(image_path), use_column_width=True)

            # æ˜¾ç¤ºä¸‹è½½æŒ‰é’®
            with open(image_path, "rb") as f:
                image_bytes = f.read()

            st.download_button(
                label="ğŸ“¥ ä¸‹è½½è¯äº‘å›¾",
                data=image_bytes,
                file_name=f"{selected_file}.png",
                mime="image/png",
            )

            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            with st.expander("ğŸ“Š æŸ¥çœ‹å…¶ä»–æ—¶é—´èŒƒå›´", expanded=False):
                # æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨çš„æ—¶é—´èŒƒå›´
                st.markdown("#### å¯ç”¨çš„è¯äº‘å›¾ï¼š")
                cols = st.columns(4)
                for idx, file in enumerate(month_options):
                    with cols[idx % 4]:
                        if file == selected_file:
                            st.markdown(f"**âœ“ {month_display[file]}**")
                        else:
                            st.markdown(f"- {month_display[file]}")
        else:
            st.error(f"è¯äº‘å›¾æ–‡ä»¶ä¸å­˜åœ¨ï¼š{image_path}")
    else:
        st.warning("è¯·é€‰æ‹©è¦æŸ¥çœ‹çš„æ—¶é—´èŒƒå›´")


@register_page("æ•°æ®å¤„ç†å·¥å…·")
def page_tools_placeholder():
    st.title("æ•°æ®å¤„ç†å·¥å…·ï¼ˆå ä½ï¼‰")
    st.info("åç»­å¯æ·»åŠ æ¸…æ´—ã€è½¬æ¢ä¸å¯¼å‡ºå·¥å…·ã€‚")


@register_page("JSONæ•°æ®åˆ†æ")
def page_json_analysis():
    st.title("JSONæ•°æ®åˆ†æå·¥å…·")
    st.markdown("""
    æœ¬å·¥å…·ç”¨äºåˆ†æå¾®åšçƒ­æœJSONæ•°æ®ï¼Œç”Ÿæˆç»Ÿè®¡å›¾è¡¨å’Œå¯è§†åŒ–æŠ¥å‘Šã€‚

    **æ”¯æŒçš„æ•°æ®æ ¼å¼ï¼š**
    - åŸå§‹æ•°æ®æ ¼å¼ï¼ˆåŒ…å« `date`, `count`, `data` å­—æ®µï¼‰
    - æŸ¥è¯¢ç»“æœæ ¼å¼ï¼ˆåŒ…å« `query_time`, `result_count`, `results` å­—æ®µï¼‰
    - æ•°æ®åˆ—è¡¨æ ¼å¼
    """)

    # æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
    st.markdown("### 1. é€‰æ‹©æ•°æ®æ–‡ä»¶")
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ JSONæ–‡ä»¶", type=["json"], help="é€‰æ‹©è¦åˆ†æçš„JSONæ•°æ®æ–‡ä»¶"
    )

    # æˆ–è€…è¾“å…¥æ–‡ä»¶è·¯å¾„
    col1, col2 = st.columns(2)
    with col1:
        file_path = st.text_input(
            "æˆ–è¾“å…¥æ–‡ä»¶è·¯å¾„",
            placeholder="ä¾‹å¦‚ï¼šdata/2025-01/2025-01-01.json",
            help="ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„è·¯å¾„",
        )

    with col2:
        font_name = st.text_input(
            "å›¾è¡¨å­—ä½“", value="Maple Mono NF CN", help="ç”¨äºå›¾è¡¨æ˜¾ç¤ºçš„å­—ä½“åç§°"
        )

    # åˆ†æé€‰é¡¹
    st.markdown("### 2. åˆ†æé€‰é¡¹")
    col3, col4, col5 = st.columns(3)
    with col3:
        generate_charts = st.checkbox("ç”Ÿæˆå›¾è¡¨", value=True)
    with col4:
        generate_report = st.checkbox("ç”Ÿæˆåˆ†ææŠ¥å‘Š", value=True)
    with col5:
        high_resolution = st.checkbox("é«˜åˆ†è¾¨ç‡å›¾è¡¨", value=True)

    # æ‰§è¡Œåˆ†ææŒ‰é’®
    st.markdown("### 3. æ‰§è¡Œåˆ†æ")
    analyze_button = st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary", use_container_width=True)

    if analyze_button:
        # ç¡®å®šè¦åˆ†æçš„æ–‡ä»¶
        json_file = None
        if uploaded_file is not None:
            # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
            import os
            import tempfile

            with tempfile.NamedTemporaryFile(delete=False, suffix=".json") as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                json_file = tmp_file.name
                st.info(f"å·²ä¸Šä¼ æ–‡ä»¶: {uploaded_file.name}")
        elif file_path and os.path.exists(file_path):
            json_file = file_path
            st.info(f"ä½¿ç”¨æ–‡ä»¶: {file_path}")
        else:
            st.error("è¯·ä¸Šä¼ æ–‡ä»¶æˆ–è¾“å…¥æœ‰æ•ˆçš„æ–‡ä»¶è·¯å¾„")
            return

        if json_file:
            try:
                # è®¾ç½®å­—ä½“
                from src.json_analyzer import setup_font

                setup_font(font_name)

                # æ‰§è¡Œåˆ†æ
                with st.spinner("æ­£åœ¨åˆ†ææ•°æ®ï¼Œè¯·ç¨å€™..."):
                    from src.json_analyzer import analyze_json

                    # è°ƒç”¨åˆ†æå‡½æ•°
                    analyze_json(json_file)

                st.success("âœ… åˆ†æå®Œæˆï¼")

                # æ˜¾ç¤ºè¾“å‡ºä¿¡æ¯
                st.markdown("### 4. åˆ†æç»“æœ")

                # è·å–è¾“å‡ºç›®å½•ï¼ˆåŸºäºæ–‡ä»¶åï¼‰
                import datetime
                from pathlib import Path

                file_name = Path(json_file).stem
                output_dir = Path("output") / f"{file_name}"

                if output_dir.exists():
                    st.info(f"åˆ†æç»“æœå·²ä¿å­˜åˆ°: `{output_dir}`")

                    # åˆ—å‡ºç”Ÿæˆçš„å›¾è¡¨æ–‡ä»¶
                    png_files = list(output_dir.glob("*.png"))
                    if png_files:
                        st.markdown("**ç”Ÿæˆçš„å›¾è¡¨ï¼š**")
                        cols = st.columns(3)
                        for idx, png_file in enumerate(png_files[:6]):  # æœ€å¤šæ˜¾ç¤º6ä¸ª
                            with cols[idx % 3]:
                                st.image(
                                    str(png_file),
                                    caption=png_file.name,
                                    use_column_width=True,
                                )

                        if len(png_files) > 6:
                            st.info(f"è¿˜æœ‰ {len(png_files) - 6} ä¸ªå›¾è¡¨æœªæ˜¾ç¤º")

                    # æ£€æŸ¥åˆ†ææŠ¥å‘Š
                    report_file = output_dir / "analysis_report.txt"
                    if report_file.exists():
                        with open(report_file, "r", encoding="utf-8") as f:
                            report_content = f.read()

                        with st.expander("ğŸ“„ æŸ¥çœ‹åˆ†ææŠ¥å‘Š", expanded=False):
                            st.text(report_content)

                        # ä¸‹è½½æŒ‰é’®
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½åˆ†ææŠ¥å‘Š",
                            data=report_content,
                            file_name="analysis_report.txt",
                            mime="text/plain",
                        )

                    # æä¾›ä¸‹è½½æ‰€æœ‰ç»“æœçš„é€‰é¡¹
                    st.markdown("**ä¸‹è½½æ‰€æœ‰ç»“æœï¼š**")

                    # åˆ›å»ºZIPæ–‡ä»¶
                    import io
                    import zipfile

                    zip_buffer = io.BytesIO()
                    with zipfile.ZipFile(
                        zip_buffer, "w", zipfile.ZIP_DEFLATED
                    ) as zip_file:
                        for file_path in output_dir.glob("*"):
                            if file_path.is_file():
                                zip_file.write(file_path, file_path.name)

                    zip_buffer.seek(0)

                    st.download_button(
                        label="ğŸ“¦ ä¸‹è½½æ‰€æœ‰å›¾è¡¨å’ŒæŠ¥å‘Š (ZIP)",
                        data=zip_buffer,
                        file_name=f"analysis_results_{file_name}.zip",
                        mime="application/zip",
                    )

                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if uploaded_file is not None:
                    import os

                    os.unlink(json_file)

            except Exception as e:
                st.error(f"åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
                import traceback

                with st.expander("æŸ¥çœ‹é”™è¯¯è¯¦æƒ…"):
                    st.code(traceback.format_exc())

    # ç¤ºä¾‹æ•°æ®
    with st.expander("ğŸ“‹ æŸ¥çœ‹ç¤ºä¾‹JSONæ ¼å¼", expanded=False):
        st.code(
            """{
    "date": "2025-01-01",
    "count": 50,
    "data": [
        {
            "rank": 1,
            "title": "ç¤ºä¾‹çƒ­æœæ ‡é¢˜",
            "category": "æ˜æ˜Ÿ",
            "heat": 1234567.8,
            "reads": 9876543,
            "discussions": 12345,
            "originals": 6789
        }
        // ... æ›´å¤šæ•°æ®
    ]
}""",
            language="json",
        )


# -------- ä¸»å…¥å£ -------- #
def main():
    st.sidebar.title("åŠŸèƒ½å¯¼èˆª")
    page_name = st.sidebar.selectbox("é€‰æ‹©é¡µé¢", options=list(PAGES.keys()))

    # æ·»åŠ ä¾§è¾¹æ ä¿¡æ¯
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ“Š é¡¹ç›®ä¿¡æ¯")
    st.sidebar.info("**å¾®åšçƒ­æœæ•°æ®åˆ†æç³»ç»Ÿ**\n\nå®æ—¶è·å–å’Œåˆ†æå¾®åšçƒ­æœè¶‹åŠ¿")

    st.sidebar.markdown("### ğŸ“– ä½¿ç”¨è¯´æ˜")
    with st.sidebar.expander("å®æ—¶çƒ­æœ", expanded=False):
        st.markdown("""
        - è·å–å¾®åšå®æ—¶ Top 50 çƒ­æœ
        - æ”¯æŒç¼“å­˜åŠ é€Ÿ
        - å¯ä¸‹è½½ JSON æ•°æ®
        """)

    with st.sidebar.expander("å†å²æ•°æ®å¯è§†åŒ–", expanded=False):
        st.markdown("""
        - æŸ¥çœ‹å†å²è¯äº‘å›¾
        - æŒ‰å…³é”®è¯/ç±»å‹åˆ†æ
        - æ”¯æŒæœˆåº¦/å­£åº¦/å¹´åº¦
        """)

    with st.sidebar.expander("æ•°æ®å¤„ç†", expanded=False):
        st.markdown("""
        - æ•°æ®æ¸…æ´—ä¸è½¬æ¢
        - æ‰¹é‡å¯¼å‡ºå·¥å…·
        - è‡ªå®šä¹‰åˆ†æ
        """)

    st.sidebar.markdown("---")
    st.sidebar.markdown("### âš™ï¸ ç³»ç»ŸçŠ¶æ€")
    import os
    from pathlib import Path

    # ç»Ÿè®¡æ•°æ®
    data_dir = Path("data")
    output_dir = Path("output/word_clouds")

    if data_dir.exists():
        json_files = list(data_dir.glob("**/*.json"))
        st.sidebar.success(f"âœ“ å·²å­˜å‚¨ {len(json_files)} ä¸ªæ•°æ®æ–‡ä»¶")
    else:
        st.sidebar.warning("âš  æ•°æ®ç›®å½•ä¸å­˜åœ¨")

    if output_dir.exists():
        img_files = list(output_dir.glob("**/*.png"))
        st.sidebar.success(f"âœ“ å·²ç”Ÿæˆ {len(img_files)} å¼ è¯äº‘å›¾")
    else:
        st.sidebar.warning("âš  è¯äº‘å›¾ç›®å½•ä¸å­˜åœ¨")

    PAGES[page_name]()


if __name__ == "__main__":
    main()
