import json
import sys
import threading
import time
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List

import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st

# å…¼å®¹åœ¨ä¸åŒå·¥ä½œç›®å½•ä¸‹è¿è¡Œ Streamlitï¼šç¡®ä¿é¡¹ç›®æ ¹ç›®å½•åŠ å…¥ sys.path
PROJECT_ROOT = Path(__file__).resolve().parents[2]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

# å¯¼å…¥å·²æœ‰çˆ¬è™«ï¼ˆå…¼å®¹ä¸åŒå·¥ä½œç›®å½•ï¼‰
try:
    from src.scrap import RealtimeHotScraper
except ModuleNotFoundError:
    ALT_SRC = PROJECT_ROOT / "src"
    if str(ALT_SRC) not in sys.path:
        sys.path.insert(0, str(ALT_SRC))
    from scrap import RealtimeHotScraper

# å¯¼å…¥json_analyzeræ¨¡å—
try:
    from src.json_analyzer import (
        analyze_data,
        analyze_json,
        basic_analysis,
        load_json_data,
        setup_font,
    )
except ModuleNotFoundError:
    from json_analyzer import (
        analyze_data,
        analyze_json,
        basic_analysis,
        load_json_data,
        setup_font,
    )

# å¯¼å…¥DataQueryæ¨¡å—
try:
    from src.data_query import DataQuery
except ModuleNotFoundError:
    from data_query import DataQuery

# è®¾ç½®é¡µé¢å¸ƒå±€ä¸ºå®½å±æ¨¡å¼
st.set_page_config(
    page_title="å¾®åšçƒ­æœæ•°æ®åˆ†æç³»ç»Ÿ",
    page_icon="ğŸ“Š",
    layout="wide",  # ä½¿ç”¨å®½å±å¸ƒå±€
    initial_sidebar_state="expanded",
)

# -------- é¡µé¢æ³¨å†Œä¸è·¯ç”±ï¼ˆå¯æ‰©å±•ï¼‰ -------- #
PAGES = {}


def register_page(name: str):
    def decorator(func):
        PAGES[name] = func
        return func

    return decorator


# -------- å®æ—¶çƒ­æœé¡µé¢ -------- #
@st.cache_resource
def get_realtime_scraper(timeout: int = 30, max_retries: int = 3, delay: float = 1.0):
    """ç¼“å­˜çˆ¬è™«å®ä¾‹"""
    return RealtimeHotScraper(timeout=timeout, max_retries=max_retries, delay=delay)


@st.cache_resource
def get_data_query():
    """ç¼“å­˜DataQueryå®ä¾‹"""
    return DataQuery()


@st.cache_data(ttl=300)  # ç¼“å­˜5åˆ†é’Ÿ
def fetch_realtime_data(
    timeout: int = 30,
    max_retries: int = 3,
    delay: float = 1.0,
    force_refresh: bool = False,
):
    """è·å–å®æ—¶çƒ­æœæ•°æ®ï¼Œç¼“å­˜5åˆ†é’Ÿ"""
    scraper = get_realtime_scraper(timeout, max_retries, delay)
    # å¦‚æœå¼ºåˆ¶åˆ·æ–°ï¼Œä¸ä½¿ç”¨ç¼“å­˜
    return scraper.fetch_realtime_top50(use_cache=not force_refresh)


@register_page("å®æ—¶çƒ­æœ Top50")
def page_realtime_hot():
    st.title("å¾®åšå®æ—¶çƒ­æœ Top50")

    # å‚æ•°è®¾ç½®ï¼ˆä½¿ç”¨ columns æ’åˆ—ï¼‰
    col_a, col_b, col_c, col_d = st.columns(4)
    with col_a:
        timeout = st.number_input("è¯·æ±‚è¶…æ—¶(s)", min_value=5, max_value=120, value=30)
    with col_b:
        max_retries = st.number_input(
            "æœ€å¤§é‡è¯•æ¬¡æ•°", min_value=1, max_value=10, value=3
        )
    with col_c:
        delay = st.number_input(
            "é‡è¯•é—´éš”(s)", min_value=0.0, max_value=10.0, value=1.0, step=0.5
        )
    with col_d:
        refresh_btn = st.button("ğŸ”„ åˆ·æ–°æ•°æ®", help="å¼ºåˆ¶åˆ·æ–°çƒ­æœæ•°æ®ï¼ˆå¿½ç•¥ç¼“å­˜ï¼‰")

    # è‡ªåŠ¨è·å–æ•°æ®æˆ–åœ¨ç”¨æˆ·ç‚¹å‡»åˆ·æ–°æ—¶é‡æ–°è·å–
    if refresh_btn:
        # æ¸…ç©ºç¼“å­˜å¹¶é‡æ–°è·å–
        st.cache_data.clear()
        items: List[Dict[str, Any]] = fetch_realtime_data(
            timeout, max_retries, delay, force_refresh=True
        )
    else:
        # é¦–æ¬¡åŠ è½½æˆ–æ˜¾ç¤ºç¼“å­˜æ•°æ®
        placeholder = st.empty()

        # æ˜¾ç¤ºåŠ è½½æç¤º
        with placeholder.container():
            st.info("â³ æ­£åœ¨è·å–å®æ—¶çƒ­æœæ•°æ®ï¼Œè¯·ç¨å€™â€¦")

        # åå°è·å–æ•°æ®
        items = fetch_realtime_data(timeout, max_retries, delay, force_refresh=False)
        placeholder.empty()

    if not items:
        st.error("âŒ æœªè·å–åˆ°æ•°æ®ã€‚è¯·å°è¯•ä»¥ä¸‹æ“ä½œï¼š")
        st.markdown("""
        1. æ£€æŸ¥ç½‘ç»œè¿æ¥
        2. ç¨åé‡è¯•
        3. åœ¨ç»ˆç«¯è¿è¡Œï¼š`python -m playwright install chromium`
        4. æˆ–åœ¨å‘½ä»¤è¡Œè¿è¡Œï¼š`python src/scrap.py realtime` é¢„å…ˆè·å–æ•°æ®ç¼“å­˜
        """)
        st.info(
            "ğŸ“ ä½ ä¹Ÿå¯ä»¥åœ¨å·¥ä½œç›®å½•æŸ¥çœ‹ debug_realtime_page_playwright.html ä»¥æ£€æŸ¥é¡µé¢ç»“æ„ã€‚"
        )
        return

    # è·å–æ—¶é—´æˆ³
    from datetime import datetime

    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    st.success(f"âœ… æˆåŠŸè·å– {len(items)} æ¡çƒ­æœ (æ›´æ–°æ—¶é—´: {current_time})")

    # å±•ç¤ºè¡¨æ ¼
    df = pd.DataFrame(items)
    display_cols = ["rank", "title"]

    # ä½¿ç”¨HTMLè¡¨æ ¼å®ç°ç¾åŒ–
    html_table = "<table style='width:100%; border-collapse: collapse;'>"
    html_table += "<thead><tr style='background-color: #f0f0f0;'>"
    html_table += "<th style='text-align:center; padding:10px; border-bottom:2px solid #ddd; font-weight:bold;'>æ’å</th>"
    html_table += "<th style='text-align:left; padding:10px; border-bottom:2px solid #ddd; font-weight:bold;'>çƒ­æœæ ‡é¢˜</th>"
    html_table += "</tr></thead><tbody>"

    for idx, (_, row) in enumerate(df[display_cols].iterrows()):
        # äº¤æ›¿è¡Œé¢œè‰²
        bg_color = "#fafafa" if idx % 2 == 0 else "white"
        html_table += f"<tr style='background-color: {bg_color};'>"
        html_table += f"<td style='text-align:center; padding:8px; border-bottom:1px solid #eee; font-weight:bold;'>{row['rank']}</td>"
        html_table += f"<td style='text-align:left; padding:8px; border-bottom:1px solid #eee;'>{row['title']}</td>"
        html_table += "</tr>"

    html_table += "</tbody></table>"
    st.markdown(html_table, unsafe_allow_html=True)

    # åˆ†åˆ—æ˜¾ç¤ºä¸‹è½½å’Œå…¶ä»–é€‰é¡¹
    col1, col2, col3 = st.columns(3)

    with col1:
        # ä¸‹è½½ JSON
        json_bytes = json.dumps(items, ensure_ascii=False, indent=2).encode("utf-8")
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½ä¸º JSON",
            data=json_bytes,
            file_name="weibo_realtime_top50.json",
            mime="application/json",
        )

    with col2:
        # ä¸‹è½½ä¸º CSV
        csv_bytes = (
            df[display_cols].to_csv(index=False, encoding="utf-8-sig").encode("utf-8")
        )
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½ä¸º CSV",
            data=csv_bytes,
            file_name="weibo_realtime_top50.csv",
            mime="text/csv",
        )

    with col3:
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        if st.button("ğŸ“Š æ˜¾ç¤ºç»Ÿè®¡", help="æ˜¾ç¤ºæ›´å¤šç»Ÿè®¡ä¿¡æ¯"):
            st.subheader("æ•°æ®ç»Ÿè®¡")
            st.write(f"**æ€»æ¡æ•°**: {len(items)}")
            st.write(f"**æ’åèŒƒå›´**: {df['rank'].min()} - {df['rank'].max()}")


# -------- å•æ—¥æ•°æ®åˆ†æé¡µé¢ -------- #
@register_page("å•æ—¥çƒ­æœåˆ†æ ")
def page_daily_analysis():
    st.title("å•æ—¥çƒ­æœæ•°æ®åˆ†æ")

    # é€‰æ‹©æ—¥æœŸ
    data_processed_dir = Path("data_processed")

    if not data_processed_dir.exists():
        st.error("data_processed ç›®å½•ä¸å­˜åœ¨")
        return

    # è·å–æ‰€æœ‰å¯ç”¨çš„æ—¥æœŸ
    available_dates = []
    for year_folder in sorted(data_processed_dir.glob("202*")):
        for json_file in sorted(year_folder.glob("*.json")):
            date_str = json_file.stem
            available_dates.append((date_str, str(json_file)))

    if not available_dates:
        st.error("æ²¡æœ‰å¯ç”¨çš„æ•°æ®æ–‡ä»¶")
        return

    # é€‰æ‹©æ—¥æœŸ
    col1, col2, col3 = st.columns([2, 1, 1])
    with col1:
        selected_date, json_path = st.selectbox(
            "é€‰æ‹©åˆ†ææ—¥æœŸ", options=available_dates, format_func=lambda x: x[0]
        )

    with col2:
        analysis_button = st.button(
            "ğŸ”„ ç”Ÿæˆåˆ†æ", help="è°ƒç”¨ json_analyzer ç”Ÿæˆå®Œæ•´åˆ†æå›¾è¡¨"
        )

    with col3:
        if st.button("ğŸ”ƒ åˆ·æ–°", help="åˆ·æ–°é¡µé¢"):
            st.rerun()

    # å½“ç‚¹å‡»ç”Ÿæˆåˆ†ææŒ‰é’®æ—¶
    if analysis_button:
        with st.spinner("æ­£åœ¨ç”Ÿæˆåˆ†æ..."):
            try:
                import io
                from contextlib import redirect_stdout

                # æ•è· analyze_json çš„è¾“å‡º
                f = io.StringIO()
                with redirect_stdout(f):
                    analyze_json(json_path)

                output_log = f.getvalue()
                st.success("âœ… åˆ†æå®Œæˆï¼")

                # æ˜¾ç¤ºè¾“å‡ºæ—¥å¿—
                with st.expander("ğŸ“‹ åˆ†ææ—¥å¿—"):
                    st.code(output_log, language="text")

            except Exception as e:
                st.error(f"åˆ†æå¤±è´¥: {str(e)}")
                import traceback

                st.error(traceback.format_exc())
                return

    # æ˜¾ç¤ºç”Ÿæˆçš„åˆ†æç»“æœ
    from datetime import datetime

    # æ„é€ è¾“å‡ºç›®å½•è·¯å¾„
    date_obj = datetime.strptime(selected_date, "%Y-%m-%d")
    output_dir = Path("output") / selected_date

    if not output_dir.exists():
        st.info("ğŸ‘‰ è¯·å…ˆç‚¹å‡» 'ğŸ”„ ç”Ÿæˆåˆ†æ' æŒ‰é’®æ¥ç”Ÿæˆåˆ†æç»“æœ")
        return

    # æŸ¥æ‰¾æ‰€æœ‰ç”Ÿæˆçš„ PNG å›¾è¡¨
    chart_files = sorted(output_dir.glob("*.png"))

    if not chart_files:
        st.warning("æ²¡æœ‰ç”Ÿæˆçš„å›¾è¡¨")
        return

    # åˆ›å»ºé€‰é¡¹å¡æ˜¾ç¤ºå„ä¸ªå›¾è¡¨
    st.markdown("### ğŸ“Š åˆ†æå›¾è¡¨")

    # ä¸ºæ¯ä¸ªå›¾è¡¨åˆ›å»ºé€‰é¡¹å¡
    if len(chart_files) > 0:
        tabs = st.tabs(
            [
                f.stem.replace(f"{selected_date}_", "").replace("_", " ")
                for f in chart_files
            ]
        )

        for tab, chart_file in zip(tabs, chart_files):
            with tab:
                # ç›´æ¥ä½¿ç”¨æ–‡ä»¶è·¯å¾„æ˜¾ç¤ºå›¾ç‰‡ï¼Œé¿å…å­—èŠ‚æµè§£ç é—®é¢˜
                st.image(
                    str(chart_file), use_column_width=True, caption=chart_file.name
                )

                # æä¾›ä¸‹è½½æŒ‰é’®ï¼ˆè¯»å–å­—èŠ‚ä¾›ä¸‹è½½ï¼‰
                try:
                    with open(chart_file, "rb") as f:
                        image_data = f.read()
                    st.download_button(
                        f"ğŸ“¥ ä¸‹è½½ {chart_file.name}",
                        data=image_data,
                        file_name=chart_file.name,
                        mime="image/png",
                    )
                except Exception as e:
                    st.warning(f"æ— æ³•æä¾›ä¸‹è½½ï¼š{e}")

    # æ˜¾ç¤ºåˆ†ææŠ¥å‘Š
    report_file = output_dir / "analysis_report.txt"
    if report_file.exists():
        st.markdown("### ğŸ“„ åˆ†ææŠ¥å‘Š")
        with open(report_file, "r", encoding="utf-8") as f:
            report_content = f.read()

        with st.expander("å±•å¼€æŸ¥çœ‹å®Œæ•´æŠ¥å‘Š"):
            st.text(report_content)

        # æä¾›æŠ¥å‘Šä¸‹è½½
        st.download_button(
            "ğŸ“¥ ä¸‹è½½åˆ†ææŠ¥å‘Š",
            data=report_content.encode("utf-8"),
            file_name=f"{selected_date}_analysis_report.txt",
            mime="text/plain",
        )


# -------- å…³é”®è¯å…±ç°ç½‘ç»œé¡µé¢ -------- #
@register_page("å¹´åº¦å…³é”®è¯ç½‘ç»œ")
def page_keyword_network():
    st.title("å…³é”®è¯å…±ç°ç½‘ç»œåˆ†æ")

    network_data_dir = Path("output/word_networks/data")

    if not network_data_dir.exists():
        st.error("ç½‘ç»œæ•°æ®ç›®å½•ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ word_network.py")
        return

    # è·å–å¯ç”¨çš„ç½‘ç»œæ•°æ®
    available_networks = []
    for json_file in sorted(network_data_dir.glob("nodes_*.json")):
        year = json_file.stem.replace("nodes_", "")
        available_networks.append(year)

    if not available_networks:
        st.error("æ²¡æœ‰å¯ç”¨çš„ç½‘ç»œæ•°æ®")
        return

    col1, col2 = st.columns([2, 1])

    with col1:
        selected_year = st.selectbox(
            "é€‰æ‹©å¹´ä»½", options=available_networks, format_func=lambda x: f"{x} å¹´"
        )

    with col2:
        if st.button("ğŸ”„ åˆ·æ–°", help="é‡æ–°åŠ è½½æ•°æ®"):
            st.rerun()

    # åŠ è½½èŠ‚ç‚¹å’Œè¾¹æ•°æ®
    try:
        with open(
            network_data_dir / f"nodes_{selected_year}.json", "r", encoding="utf-8"
        ) as f:
            nodes_data = json.load(f)

        with open(
            network_data_dir / f"edges_{selected_year}.json", "r", encoding="utf-8"
        ) as f:
            edges_data = json.load(f)
    except Exception as e:
        st.error(f"åŠ è½½å¤±è´¥: {e}")
        return

    # ========== TAB è§†å›¾ ==========
    tab1, tab2, tab3 = st.tabs(["ğŸ–¼ï¸ ç½‘ç»œå›¾", "ğŸ“Š ç»Ÿè®¡", "ğŸ“‹ æ•°æ®è¡¨"])

    with tab1:
        st.subheader("å…³é”®è¯å…±ç°ç½‘ç»œå¯è§†åŒ–")

        # æ˜¾ç¤ºç½‘ç»œå›¾
        network_img_path = (
            Path("output/word_networks/figures")
            / f"keyword_network_{selected_year}.png"
        )
        if network_img_path.exists():
            st.image(str(network_img_path), use_column_width=True)

            with open(network_img_path, "rb") as f:
                st.download_button(
                    "ğŸ“¥ ä¸‹è½½ç½‘ç»œå›¾",
                    f.read(),
                    f"keyword_network_{selected_year}.png",
                    "image/png",
                )
        else:
            st.warning("ç½‘ç»œå›¾æ–‡ä»¶ä¸å­˜åœ¨")

    with tab2:
        st.subheader("ç½‘ç»œç»Ÿè®¡")

        nodes_count = len(nodes_data)
        edges_count = len(edges_data)

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("èŠ‚ç‚¹æ•°ï¼ˆå…³é”®è¯ï¼‰", nodes_count)

        with col2:
            st.metric("è¾¹æ•°ï¼ˆå…±ç°å…³ç³»ï¼‰", edges_count)

        with col3:
            if edges_count > 0:
                avg_cooccur = np.mean([e["weight"] for e in edges_data])
                st.metric("å¹³å‡å…±ç°åº¦", f"{avg_cooccur:.2f}")
            else:
                st.metric("å¹³å‡å…±ç°åº¦", "0")

        with col4:
            if nodes_count > 0:
                avg_freq = np.mean([n["frequency"] for n in nodes_data])
                st.metric("å¹³å‡å…³é”®è¯é¢‘æ¬¡", f"{avg_freq:.2f}")
            else:
                st.metric("å¹³å‡å…³é”®è¯é¢‘æ¬¡", "0")

        # é¢‘æ¬¡TOP 10
        import plotly.express as px

        top_nodes = sorted(nodes_data, key=lambda x: x["frequency"], reverse=True)[:10]

        fig = px.bar(
            x=[n["frequency"] for n in top_nodes],
            y=[n["keyword"] for n in top_nodes],
            orientation="h",
            title="å…³é”®è¯é¢‘æ¬¡ Top 10",
            color=[n["frequency"] for n in top_nodes],
            color_continuous_scale="Viridis",
        )
        fig.update_yaxes(automargin=True)
        st.plotly_chart(fig, use_container_width=True)

        # å…±ç°åº¦æœ€é«˜çš„å…³ç³»
        top_edges = sorted(edges_data, key=lambda x: x["weight"], reverse=True)[:10]

        edge_labels = [f"{e['source']} - {e['target']}" for e in top_edges]
        edge_weights = [e["weight"] for e in top_edges]

        fig = px.bar(
            x=edge_weights,
            y=edge_labels,
            orientation="h",
            title="å…±ç°å…³ç³» Top 10",
            color=edge_weights,
            color_continuous_scale="Reds",
        )
        fig.update_yaxes(automargin=True)
        st.plotly_chart(fig, use_container_width=True)

    with tab3:
        st.subheader("èŠ‚ç‚¹å’Œè¾¹æ•°æ®")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("#### å…³é”®è¯èŠ‚ç‚¹")
            nodes_df = pd.DataFrame(nodes_data).sort_values(
                "frequency", ascending=False
            )
            st.dataframe(nodes_df, use_container_width=True, height=400)

            csv = nodes_df.to_csv(index=False, encoding="utf-8-sig").encode("utf-8")
            st.download_button(
                "ğŸ“¥ ä¸‹è½½èŠ‚ç‚¹æ•°æ®", csv, f"nodes_{selected_year}.csv", "text/csv"
            )

        with col2:
            st.markdown("#### å…±ç°å…³ç³»")
            edges_df = pd.DataFrame(edges_data).sort_values("weight", ascending=False)
            st.dataframe(edges_df, use_container_width=True, height=400)

            csv = edges_df.to_csv(index=False, encoding="utf-8-sig").encode("utf-8")
            st.download_button(
                "ğŸ“¥ ä¸‹è½½è¾¹æ•°æ®", csv, f"edges_{selected_year}.csv", "text/csv"
            )


# -------- 2025å¹´åº¦æŠ¥å‘Šé¡µé¢ -------- #
@register_page("2025å¹´åº¦æŠ¥å‘Š")
def page_annual_report():
    st.title("2025å¹´åº¦å¾®åšçƒ­æœåˆ†ææŠ¥å‘Š")

    # å¯¼å…¥å¹´åº¦æŠ¥å‘Šæ¨¡å—
    try:
        from src.annual_report import generate_annual_report
    except ImportError:
        from annual_report import generate_annual_report

    # è®¾ç½®å­—ä½“
    try:
        from src.json_analyzer import setup_font

        setup_font()
    except:
        pass

    # æ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4 = st.tabs(
        ["ğŸ“Š æ•°æ®æ€»è§ˆ", "ğŸ“ˆ çƒ­æœæ’å", "ğŸ”— å…³é”®è¯åˆ†æ", "ğŸ“… æ—¶é—´åˆ†å¸ƒ"]
    )

    # ç”Ÿæˆå¹´åº¦æŠ¥å‘Š
    with st.spinner("æ­£åœ¨ç”Ÿæˆå¹´åº¦æŠ¥å‘Š..."):
        report = generate_annual_report("data")

    if "error" in report:
        st.error(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {report['error']}")
        st.info("è¯·ç¡®ä¿ data ç›®å½•ä¸­æœ‰ JSON æ•°æ®æ–‡ä»¶")
        return

    summary = report.get("summary", {})

    # Tab 1: æ•°æ®æ€»è§ˆ
    with tab1:
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric(
                "ğŸ“Š æ€»è®°å½•æ•°", f"{summary.get('total_records', 0):,}", delta="æ¡çƒ­æœ"
            )

        with col2:
            st.metric(
                "ğŸ¯ ç‹¬ç‰¹æ ‡é¢˜", f"{summary.get('total_unique_titles', 0):,}", delta="ä¸ª"
            )

        with col3:
            heat_stats = summary.get("heat_stats", {})
            st.metric(
                "ğŸ”¥ å¹³å‡çƒ­åº¦",
                f"{heat_stats.get('mean', 0):.1f}",
                delta=f"ä¸­ä½æ•°: {heat_stats.get('median', 0):.1f}",
            )

        with col4:
            date_range = summary.get("date_range", {})
            st.metric(
                "ğŸ“… ç»Ÿè®¡å‘¨æœŸ",
                f"{date_range.get('start', 'N/A')} ~ {date_range.get('end', 'N/A')}",
                delta="å…±è®¡",
            )

        st.divider()

        # çƒ­åº¦ç»Ÿè®¡è¯¦æƒ…
        col1, col2 = st.columns(2)

        with col1:
            st.subheader("ğŸ”¥ çƒ­åº¦ç»Ÿè®¡è¯¦æƒ…")
            heat_stats = summary.get("heat_stats", {})

            stats_table = pd.DataFrame(
                {
                    "æŒ‡æ ‡": ["æœ€é«˜çƒ­åº¦", "æœ€ä½çƒ­åº¦", "å¹³å‡çƒ­åº¦", "ä¸­ä½æ•°", "æ ‡å‡†å·®"],
                    "æ•°å€¼": [
                        f"{heat_stats.get('max', 0):.1f}",
                        f"{heat_stats.get('min', 0):.1f}",
                        f"{heat_stats.get('mean', 0):.1f}",
                        f"{heat_stats.get('median', 0):.1f}",
                        f"{heat_stats.get('std', 0):.1f}",
                    ],
                }
            )

            st.dataframe(stats_table, use_container_width=True, hide_index=True)

        with col2:
            st.subheader("ğŸ“… æ—¶é—´åˆ†å¸ƒ")
            temporal_dist = report.get("temporal_distribution", {})

            if temporal_dist:
                # åˆ›å»ºæ—¶é—´åˆ†å¸ƒå›¾
                months = sorted(temporal_dist.keys())
                counts = [temporal_dist[m] for m in months]

                import plotly.express as px

                fig = px.line(
                    x=months,
                    y=counts,
                    markers=True,
                    title="æ¯æœˆçƒ­æœæ•°é‡è¶‹åŠ¿",
                    labels={"x": "æœˆä»½", "y": "çƒ­æœæ•°é‡"},
                )
                fig.update_xaxes(tickangle=45)
                st.plotly_chart(fig, use_container_width=True)

    # Tab 2: çƒ­æœæ’å
    with tab2:
        st.subheader("ğŸ† å…¨å¹´çƒ­åº¦æœ€é«˜çš„10æ¡çƒ­æœ")

        top_titles = summary.get("top_10_titles", [])

        if top_titles:
            # åˆ›å»ºæ’åè¡¨
            rank_data = []
            for i, item in enumerate(top_titles, 1):
                rank_data.append(
                    {
                        "æ’å": i,
                        "æ ‡é¢˜": item.get("title", ""),
                        "çƒ­åº¦": f"{item.get('heat', 0):.1f}",
                        "åœ¨æ¦œæ’å": item.get("rank", "N/A"),
                    }
                )

            df_top = pd.DataFrame(rank_data)
            st.dataframe(df_top, use_container_width=True, hide_index=True)

            # çƒ­åº¦æŸ±çŠ¶å›¾
            import plotly.express as px

            fig = px.bar(
                x=list(range(1, len(top_titles) + 1)),
                y=[item.get("heat", 0) for item in top_titles],
                labels={"x": "æ’å", "y": "çƒ­åº¦å€¼"},
                title="çƒ­åº¦æ’åå‰10çš„çƒ­æœ",
                color=[item.get("heat", 0) for item in top_titles],
                color_continuous_scale="Reds",
                text=[item.get("title", "")[:20] for item in top_titles],
            )
            fig.update_traces(textposition="outside")
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("æš‚æ— çƒ­æœæ’åæ•°æ®")

    # Tab 3: å…³é”®è¯åˆ†æ
    with tab3:
        st.subheader("ğŸ”‘ å…³é”®è¯é¢‘ç‡åˆ†æ")

        keyword_freq = summary.get("keyword_frequency", {})

        if keyword_freq:
            # å…³é”®è¯æ’è¡Œ
            col1, col2 = st.columns([2, 1])

            with col1:
                # çƒ­åŠ›å›¾
                import plotly.express as px

                top_keywords = dict(
                    sorted(keyword_freq.items(), key=lambda x: x[1], reverse=True)[:20]
                )

                fig = px.bar(
                    x=list(top_keywords.values()),
                    y=list(top_keywords.keys()),
                    orientation="h",
                    title="å…³é”®è¯é¢‘ç‡ Top 20",
                    labels={"x": "å‡ºç°æ¬¡æ•°", "y": "å…³é”®è¯"},
                    color=list(top_keywords.values()),
                    color_continuous_scale="Viridis",
                )
                fig.update_yaxes(automargin=True)
                st.plotly_chart(fig, use_container_width=True)

            with col2:
                st.metric("æ€»å…³é”®è¯æ•°", len(keyword_freq))
                st.metric(
                    "æœ€é¢‘ç¹å…³é”®è¯",
                    max(keyword_freq, key=keyword_freq.get) if keyword_freq else "N/A",
                )
                st.metric("æœ€é«˜é¢‘ç‡", max(keyword_freq.values()) if keyword_freq else 0)

            # å…³é”®è¯è¡¨
            st.markdown("#### ğŸ“‹ å…³é”®è¯åˆ—è¡¨")
            keyword_df = pd.DataFrame(
                [
                    {"å…³é”®è¯": k, "é¢‘ç‡": v}
                    for k, v in sorted(
                        keyword_freq.items(), key=lambda x: x[1], reverse=True
                    )
                ]
            )
            st.dataframe(keyword_df, use_container_width=True, height=400)
        else:
            st.info("æš‚æ— å…³é”®è¯æ•°æ®")

        # å…³é”®è¯ç½‘ç»œ
        st.markdown("---")
        st.subheader("ğŸ”— å…³é”®è¯å…±ç°ç½‘ç»œ")

        keyword_network = report.get("keyword_network", {})

        if keyword_network:
            st.info(f"å…±æ£€æµ‹åˆ° {len(keyword_network)} ä¸ªæ ¸å¿ƒå…³é”®è¯èŠ‚ç‚¹")

            # æ˜¾ç¤ºç½‘ç»œæ•°æ®
            network_data = []
            for keyword, related in keyword_network.items():
                network_data.append(
                    {
                        "ä¸­å¿ƒè¯": keyword,
                        "ç›¸å…³è¯": ", ".join(related),
                        "è¿æ¥æ•°": len(related),
                    }
                )

            df_network = pd.DataFrame(network_data).sort_values(
                "è¿æ¥æ•°", ascending=False
            )
            st.dataframe(df_network, use_container_width=True, hide_index=True)
        else:
            st.info("æš‚æ— å…³é”®è¯ç½‘ç»œæ•°æ®")

    # Tab 4: æ—¶é—´åˆ†å¸ƒ
    with tab4:
        st.subheader("ğŸ“… æŒ‰æ—¶é—´åˆ†å¸ƒç»Ÿè®¡")

        temporal_dist = report.get("temporal_distribution", {})

        if temporal_dist:
            col1, col2 = st.columns([2, 1])

            with col1:
                # æœˆåº¦åˆ†å¸ƒè¡¨
                months = sorted(temporal_dist.keys())
                month_data = [{"æœˆä»½": m, "çƒ­æœæ•°": temporal_dist[m]} for m in months]

                df_temporal = pd.DataFrame(month_data)
                st.dataframe(df_temporal, use_container_width=True, hide_index=True)

            with col1:
                # ç´¯ç§¯å›¾
                import plotly.graph_objects as go

                cumulative = np.cumsum([temporal_dist[m] for m in months])

                fig = go.Figure()
                fig.add_trace(
                    go.Scatter(
                        x=months,
                        y=cumulative,
                        mode="lines+markers",
                        fill="tozeroy",
                        name="ç´¯ç§¯çƒ­æœæ•°",
                    )
                )
                fig.update_layout(
                    title="çƒ­æœæ•°ç´¯ç§¯è¶‹åŠ¿",
                    xaxis_title="æœˆä»½",
                    yaxis_title="ç´¯ç§¯æ•°é‡",
                    hovermode="x unified",
                )
                fig.update_xaxes(tickangle=45)
                st.plotly_chart(fig, use_container_width=True)

            with col2:
                st.metric("å¹³å‡æœˆåº¦", f"{np.mean(list(temporal_dist.values())):.0f}")
                st.metric("æœ€é«˜æœˆä»½", f"{max(temporal_dist.values())}")
                st.metric("æœ€ä½æœˆä»½", f"{min(temporal_dist.values())}")
        else:
            st.info("æš‚æ— æ—¶é—´åˆ†å¸ƒæ•°æ®")

    # åº•éƒ¨ä¸‹è½½æŠ¥å‘Š
    st.divider()
    st.markdown("### ğŸ’¾ å¯¼å‡ºæŠ¥å‘Š")

    col1, col2 = st.columns(2)

    with col1:
        # å¯¼å‡º JSON
        json_report = json.dumps(report, ensure_ascii=False, indent=2)
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½å®Œæ•´æŠ¥å‘Š (JSON)",
            data=json_report.encode("utf-8"),
            file_name="annual_report_2025.json",
            mime="application/json",
        )

    with col2:
        # å¯¼å‡ºç®€è¦æ–‡æœ¬
        text_report = f"""
2025å¹´åº¦å¾®åšçƒ­æœåˆ†ææŠ¥å‘Š
{"=" * 60}

ç”Ÿæˆæ—¶é—´: {report.get("report_date", "N/A")}

ã€æ•°æ®æ¦‚è§ˆã€‘
æ€»çƒ­æœè®°å½•æ•°: {summary.get("total_records", 0)} æ¡
ç‹¬ç‰¹çƒ­æœæ•°: {summary.get("total_unique_titles", 0)} ä¸ª
ç»Ÿè®¡æ—¶é—´: {summary.get("date_range", {}).get("start", "N/A")} ~ {summary.get("date_range", {}).get("end", "N/A")}

ã€çƒ­åº¦ç»Ÿè®¡ã€‘
æœ€é«˜çƒ­åº¦: {summary.get("heat_stats", {}).get("max", 0):.1f}
æœ€ä½çƒ­åº¦: {summary.get("heat_stats", {}).get("min", 0):.1f}
å¹³å‡çƒ­åº¦: {summary.get("heat_stats", {}).get("mean", 0):.1f}
ä¸­ä½æ•°: {summary.get("heat_stats", {}).get("median", 0):.1f}

ã€Top10çƒ­æœã€‘
"""
        for i, item in enumerate(summary.get("top_10_titles", []), 1):
            text_report += (
                f"{i}. {item.get('title', 'N/A')} (çƒ­åº¦: {item.get('heat', 0):.1f})\n"
            )

        st.download_button(
            label="ğŸ“¥ ä¸‹è½½ç®€è¦æŠ¥å‘Š (TXT)",
            data=text_report.encode("utf-8"),
            file_name="annual_report_2025_summary.txt",
            mime="text/plain",
        )


# -------- è¯äº‘å›¾å¯è§†åŒ–é¡µé¢ -------- #
@register_page("è¯äº‘å›¾å¯è§†åŒ–")
def page_word_cloud_visualization():
    st.title("è¯äº‘å›¾å¯è§†åŒ–")

    import os
    from pathlib import Path

    # è·å–è¯äº‘å›¾ç›®å½•
    word_clouds_dir = Path("output/word_clouds")

    if not word_clouds_dir.exists():
        st.error("è¯äº‘å›¾ç›®å½•ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œæ•°æ®å¤„ç†ç”Ÿæˆè¯äº‘å›¾")
        return

    # å±…ä¸­æ˜¾ç¤ºé€‰é¡¹
    st.markdown("### ğŸ“Š è¯äº‘å›¾æŸ¥çœ‹å™¨")

    # åˆ›å»ºå±…ä¸­çš„é€‰é¡¹åŒºåŸŸ
    col1, col2, col3, col4, col5 = st.columns([1, 2, 2, 2, 1])

    with col2:
        # é€‰æ‹©ç±»å‹ï¼šå…³é”®è¯æˆ–ç±»å‹
        viz_type = st.selectbox(
            "é€‰æ‹©åˆ†æç»´åº¦",
            options=["å…³é”®è¯", "ç±»å‹"],
            help="å…³é”®è¯ï¼šåŸºäºçƒ­æœæ ‡é¢˜çš„è¯é¢‘åˆ†æ\nç±»å‹ï¼šåŸºäºçƒ­æœåˆ†ç±»çš„ç»Ÿè®¡",
        )

    with col3:
        # è·å–å¯ç”¨çš„æœˆä»½é€‰é¡¹
        type_folder = "keywords" if viz_type == "å…³é”®è¯" else "types"
        folder_path = word_clouds_dir / type_folder

        # æ‰«æå¯ç”¨çš„å›¾ç‰‡æ–‡ä»¶
        available_files = []
        if folder_path.exists():
            available_files = sorted(
                [
                    f.stem
                    for f in folder_path.glob("*.png")
                    if not f.name.startswith("custom_analysis")
                ]
            )

        if not available_files:
            st.warning(f"æœªæ‰¾åˆ°{viz_type}è¯äº‘å›¾")
            return

        # æ„å»ºæœˆä»½é€‰é¡¹
        month_options = []
        month_display = {}

        for filename in available_files:
            if filename.endswith("2025"):
                display_name = "å…¨å¹´æ±‡æ€» (2025)"
                month_options.append(filename)
                month_display[filename] = display_name
            elif "Q" in filename:
                quarter = filename.split("-")[-1]
                display_name = f"å­£åº¦æ±‡æ€» ({quarter})"
                month_options.append(filename)
                month_display[filename] = display_name
            elif "-" in filename:
                parts = filename.split("_")[-1].split("-")
                if len(parts) == 2:
                    year, month = parts
                    display_name = f"{year}å¹´{month}æœˆ"
                    month_options.append(filename)
                    month_display[filename] = display_name

        # é€‰æ‹©æœˆä»½
        selected_file = st.selectbox(
            "é€‰æ‹©æ—¶é—´èŒƒå›´",
            options=month_options,
            format_func=lambda x: month_display.get(x, x),
            help="é€‰æ‹©è¦æŸ¥çœ‹çš„æœˆä»½æˆ–æ±‡æ€»æœŸé—´",
        )

    with col4:
        # æ·»åŠ åˆ·æ–°æŒ‰é’®
        if st.button("ğŸ”„ åˆ·æ–°", help="é‡æ–°åŠ è½½è¯äº‘å›¾"):
            st.rerun()

    # æ˜¾ç¤ºè¯äº‘å›¾
    if selected_file:
        image_path = folder_path / f"{selected_file}.png"

        if image_path.exists():
            # å±…ä¸­æ˜¾ç¤ºè¯äº‘å›¾
            col_left, col_center, col_right = st.columns([0.5, 3, 0.5])
            with col_center:
                st.image(str(image_path), use_column_width=True)

            # æ˜¾ç¤ºä¸‹è½½æŒ‰é’®
            with open(image_path, "rb") as f:
                image_bytes = f.read()

            st.download_button(
                label="ğŸ“¥ ä¸‹è½½è¯äº‘å›¾",
                data=image_bytes,
                file_name=f"{selected_file}.png",
                mime="image/png",
            )

            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            with st.expander("ğŸ“Š æŸ¥çœ‹å…¶ä»–æ—¶é—´èŒƒå›´", expanded=False):
                # æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨çš„æ—¶é—´èŒƒå›´
                st.markdown("#### å¯ç”¨çš„è¯äº‘å›¾ï¼š")
                cols = st.columns(4)
                for idx, file in enumerate(month_options):
                    with cols[idx % 4]:
                        if file == selected_file:
                            st.markdown(f"**âœ“ {month_display[file]}**")
                        else:
                            st.markdown(f"- {month_display[file]}")
        else:
            st.error(f"è¯äº‘å›¾æ–‡ä»¶ä¸å­˜åœ¨ï¼š{image_path}")
    else:
        st.warning("è¯·é€‰æ‹©è¦æŸ¥çœ‹çš„æ—¶é—´èŒƒå›´")


@register_page("JSONæ•°æ®åˆ†æ")
def page_json_analysis():
    st.title("JSONæ•°æ®åˆ†æå·¥å…·")
    st.markdown("""
    æœ¬å·¥å…·ç”¨äºåˆ†æå¾®åšçƒ­æœJSONæ•°æ®ï¼Œç”Ÿæˆç»Ÿè®¡å›¾è¡¨å’Œå¯è§†åŒ–æŠ¥å‘Šã€‚

    **æ”¯æŒçš„æ•°æ®æ ¼å¼ï¼š**
    - åŸå§‹æ•°æ®æ ¼å¼ï¼ˆåŒ…å« `date`, `count`, `data` å­—æ®µï¼‰
    - æŸ¥è¯¢ç»“æœæ ¼å¼ï¼ˆåŒ…å« `query_time`, `result_count`, `results` å­—æ®µï¼‰
    - æ•°æ®åˆ—è¡¨æ ¼å¼
    """)

    # æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
    st.markdown("### 1. é€‰æ‹©æ•°æ®æ–‡ä»¶")
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ JSONæ–‡ä»¶", type=["json"], help="é€‰æ‹©è¦åˆ†æçš„JSONæ•°æ®æ–‡ä»¶"
    )

    # æˆ–è€…è¾“å…¥æ–‡ä»¶è·¯å¾„
    col1, col2 = st.columns(2)
    with col1:
        file_path = st.text_input(
            "æˆ–è¾“å…¥æ–‡ä»¶è·¯å¾„",
            placeholder="ä¾‹å¦‚ï¼šdata/2025-01/2025-01-01.json",
            help="ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„è·¯å¾„",
        )

    with col2:
        font_name = st.text_input(
            "å›¾è¡¨å­—ä½“", value="Maple Mono NF CN", help="ç”¨äºå›¾è¡¨æ˜¾ç¤ºçš„å­—ä½“åç§°"
        )

    # åˆ†æé€‰é¡¹
    st.markdown("### 2. åˆ†æé€‰é¡¹")
    col3, col4, col5 = st.columns(3)
    with col3:
        generate_charts = st.checkbox("ç”Ÿæˆå›¾è¡¨", value=True)
    with col4:
        generate_report = st.checkbox("ç”Ÿæˆåˆ†ææŠ¥å‘Š", value=True)
    with col5:
        high_resolution = st.checkbox("é«˜åˆ†è¾¨ç‡å›¾è¡¨", value=True)

    # æ‰§è¡Œåˆ†ææŒ‰é’®
    st.markdown("### 3. æ‰§è¡Œåˆ†æ")
    analyze_button = st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary", use_container_width=True)

    if analyze_button:
        # ç¡®å®šè¦åˆ†æçš„æ–‡ä»¶
        json_file = None
        if uploaded_file is not None:
            # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
            import os
            import tempfile

            with tempfile.NamedTemporaryFile(delete=False, suffix=".json") as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                json_file = tmp_file.name
                st.info(f"å·²ä¸Šä¼ æ–‡ä»¶: {uploaded_file.name}")
        elif file_path and os.path.exists(file_path):
            json_file = file_path
            st.info(f"ä½¿ç”¨æ–‡ä»¶: {file_path}")
        else:
            st.error("è¯·ä¸Šä¼ æ–‡ä»¶æˆ–è¾“å…¥æœ‰æ•ˆçš„æ–‡ä»¶è·¯å¾„")
            return

        if json_file:
            try:
                # è®¾ç½®å­—ä½“
                from src.json_analyzer import setup_font

                setup_font(font_name)

                # æ‰§è¡Œåˆ†æ
                with st.spinner("æ­£åœ¨åˆ†ææ•°æ®ï¼Œè¯·ç¨å€™..."):
                    from src.json_analyzer import analyze_json

                    # è°ƒç”¨åˆ†æå‡½æ•°
                    analyze_json(json_file)

                st.success("âœ… åˆ†æå®Œæˆï¼")

                # æ˜¾ç¤ºè¾“å‡ºä¿¡æ¯
                st.markdown("### 4. åˆ†æç»“æœ")

                # è·å–è¾“å‡ºç›®å½•ï¼ˆåŸºäºæ–‡ä»¶åï¼‰
                import datetime
                from pathlib import Path

                file_name = Path(json_file).stem
                output_dir = Path("output") / f"{file_name}"

                if output_dir.exists():
                    st.info(f"åˆ†æç»“æœå·²ä¿å­˜åˆ°: `{output_dir}`")

                    # åˆ—å‡ºç”Ÿæˆçš„å›¾è¡¨æ–‡ä»¶
                    png_files = list(output_dir.glob("*.png"))
                    if png_files:
                        st.markdown("**ç”Ÿæˆçš„å›¾è¡¨ï¼š**")
                        cols = st.columns(3)
                        for idx, png_file in enumerate(png_files[:6]):  # æœ€å¤šæ˜¾ç¤º6ä¸ª
                            with cols[idx % 3]:
                                st.image(
                                    str(png_file),
                                    caption=png_file.name,
                                    use_column_width=True,
                                )

                        if len(png_files) > 6:
                            st.info(f"è¿˜æœ‰ {len(png_files) - 6} ä¸ªå›¾è¡¨æœªæ˜¾ç¤º")

                    # æ£€æŸ¥åˆ†ææŠ¥å‘Š
                    report_file = output_dir / "analysis_report.txt"
                    if report_file.exists():
                        with open(report_file, "r", encoding="utf-8") as f:
                            report_content = f.read()

                        with st.expander("ğŸ“„ æŸ¥çœ‹åˆ†ææŠ¥å‘Š", expanded=False):
                            st.text(report_content)

                        # ä¸‹è½½æŒ‰é’®
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½åˆ†ææŠ¥å‘Š",
                            data=report_content,
                            file_name="analysis_report.txt",
                            mime="text/plain",
                        )

                    # æä¾›ä¸‹è½½æ‰€æœ‰ç»“æœçš„é€‰é¡¹
                    st.markdown("**ä¸‹è½½æ‰€æœ‰ç»“æœï¼š**")

                    # åˆ›å»ºZIPæ–‡ä»¶
                    import io
                    import zipfile

                    zip_buffer = io.BytesIO()
                    with zipfile.ZipFile(
                        zip_buffer, "w", zipfile.ZIP_DEFLATED
                    ) as zip_file:
                        for file_path in output_dir.glob("*"):
                            if file_path.is_file():
                                zip_file.write(file_path, file_path.name)

                    zip_buffer.seek(0)

                    st.download_button(
                        label="ğŸ“¦ ä¸‹è½½æ‰€æœ‰å›¾è¡¨å’ŒæŠ¥å‘Š (ZIP)",
                        data=zip_buffer,
                        file_name=f"analysis_results_{file_name}.zip",
                        mime="application/zip",
                    )

                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if uploaded_file is not None:
                    import os

                    os.unlink(json_file)

            except Exception as e:
                st.error(f"åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
                import traceback

                with st.expander("æŸ¥çœ‹é”™è¯¯è¯¦æƒ…"):
                    st.code(traceback.format_exc())

    # ç¤ºä¾‹æ•°æ®
    with st.expander("ğŸ“‹ æŸ¥çœ‹ç¤ºä¾‹JSONæ ¼å¼", expanded=False):
        st.code(
            """{
    "date": "2025-01-01",
    "count": 50,
    "data": [
        {
            "rank": 1,
            "title": "ç¤ºä¾‹çƒ­æœæ ‡é¢˜",
            "category": "æ˜æ˜Ÿ",
            "heat": 1234567.8,
            "reads": 9876543,
            "discussions": 12345,
            "originals": 6789
        }
        // ... æ›´å¤šæ•°æ®
    ]
}""",
            language="json",
        )


# -------- å»å¹´ä»Šæ—¥é¡µé¢ -------- #
@register_page("å»å¹´ä»Šæ—¥")
def page_random_hot_today():
    st.title("å»å¹´ä»Šæ—¥")
    st.markdown("""
    ä»å†å²æ•°æ®ä¸­éšæœºæ‰¾å‡ºä¸ä»Šå¤©æ—¥æœŸç›¸åŒæˆ–ç›¸è¿‘ï¼ˆå¹´ä»½ä¸åŒï¼‰ä¸”çƒ­åº¦è¾ƒé«˜çš„çƒ­æœã€‚

    **ç­›é€‰æ¡ä»¶ï¼š**
    - ğŸ“† æ—¥æœŸï¼šä¸ä»Šå¤©ç›¸åŒçš„æœˆæ—¥ï¼ˆè·¨è¶Šä¸åŒå¹´ä»½ï¼‰
    - ğŸ”¥ çƒ­åº¦ï¼šå¤§äº 1 çš„æ¡ç›®
    """)

    # å¯¼å…¥æ¨¡å—
    try:
        from src.random_hot_today import RandomHotToday
    except ImportError:
        from random_hot_today import RandomHotToday

    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
    col1, col2 = st.columns([3, 1])

    with col2:
        if st.button("ğŸ² æ¢ä¸€æ¡", type="primary", use_container_width=True):
            st.session_state.random_hot_today_cache = None

    with col1:
        st.markdown("### æŸ¥æ‰¾æ•°æ®")

    # ç¼“å­˜æ•°æ®ä»¥é¿å…é‡å¤æŸ¥è¯¢
    if "random_hot_today_cache" not in st.session_state:
        st.session_state.random_hot_today_cache = None

    # æ‰§è¡ŒæŸ¥è¯¢
    with st.spinner("æ­£åœ¨ä»å†å²æ•°æ®ä¸­æŸ¥æ‰¾..."):
        try:
            random_today = RandomHotToday()

            # åŠ è½½å¹¶ç­›é€‰æ•°æ®
            matching_items = random_today.load_and_filter_data()

            if not matching_items:
                st.warning("âŒ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ•°æ®")
                st.info("ğŸ’¡ è¯·ç¡®ä¿å·²åŠ è½½è¶³å¤Ÿçš„å†å²æ•°æ®")
                return

            # éšæœºé€‰æ‹©ä¸€æ¡
            selected_item = random_today.select_random_item(matching_items)

            if selected_item:
                st.session_state.random_hot_today_cache = selected_item
            else:
                st.error("æœªèƒ½é€‰æ‹©æ•°æ®")
                return

        except Exception as e:
            st.error(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {str(e)}")
            import traceback

            with st.expander("æŸ¥çœ‹é”™è¯¯è¯¦æƒ…"):
                st.code(traceback.format_exc())
            return

    # æ˜¾ç¤ºé€‰ä¸­çš„æ•°æ®
    item = st.session_state.random_hot_today_cache
    if item:
        # è·å–æ•°æ®
        title = item.get("title", "N/A")
        rank = item.get("rank", "N/A")
        date = item.get("date", "N/A")
        heat = item.get("heat", 0)
        category = item.get("category", "")
        reads = item.get("reads", 0)
        discussions = item.get("discussions", 0)
        originals = item.get("originals", 0)

        # åˆ›å»ºå¡ç‰‡å±•ç¤º
        st.markdown("---")
        st.markdown("### ğŸ† é€‰ä¸­çš„çƒ­æœ")

        # ä¸»æ ‡é¢˜åŒºåŸŸ
        col1, col2 = st.columns([4, 1])
        with col1:
            st.markdown(f"#### {title}")
        with col2:
            st.metric("çƒ­åº¦", f"{heat:.2f}")

        # è¯¦ç»†ä¿¡æ¯è¡¨æ ¼
        info_data = {
            "ğŸ“… æ—¥æœŸ": str(date),
            "ğŸ… æ’å": str(rank),
            "ğŸ·ï¸  åˆ†ç±»": category if category else "æœªåˆ†ç±»",
            "ğŸ“– é˜…è¯»é‡": f"{reads:.0f}" if reads else "N/A",
            "ğŸ’¬ è®¨è®ºé‡": f"{discussions:.0f}" if discussions else "N/A",
            "âœï¸  åŸåˆ›é‡": f"{originals:.0f}" if originals else "N/A",
        }

        # ä¸¤åˆ—æ˜¾ç¤º
        col1, col2 = st.columns(2)
        with col1:
            for key in list(info_data.keys())[:3]:
                st.markdown(f"**{key}** {info_data[key]}")
        with col2:
            for key in list(info_data.keys())[3:]:
                st.markdown(f"**{key}** {info_data[key]}")

        st.markdown("---")

        # ç»Ÿè®¡ä¿¡æ¯
        st.markdown("### ğŸ“Š æ•°æ®ç»Ÿè®¡")

        # å››ä¸ªæŒ‡æ ‡å¡
        metric_cols = st.columns(4)
        with metric_cols[0]:
            st.metric("çƒ­åº¦æ’å", f"#{rank}", delta=None)
        with metric_cols[1]:
            st.metric("çƒ­åº¦å€¼", f"{heat:.1f}", delta="ç›¸å¯¹å‚è€ƒ")
        with metric_cols[2]:
            st.metric(
                "é˜…è¯»é‡", f"{reads / 1000:.1f}K" if reads >= 1000 else f"{reads:.0f}"
            )
        with metric_cols[3]:
            st.metric("è®¨è®ºçƒ­åº¦", f"{discussions:.1f}")

        # å¯¼å‡ºé€‰é¡¹
        st.markdown("### ğŸ’¾ å¯¼å‡ºæ•°æ®")

        col1, col2, col3 = st.columns(3)

        with col1:
            # JSON å¯¼å‡º
            json_str = json.dumps(item, ensure_ascii=False, indent=2)
            st.download_button(
                label="ğŸ“¥ JSON æ ¼å¼",
                data=json_str.encode("utf-8"),
                file_name=f"hot_today_{date}.json",
                mime="application/json",
            )

        with col2:
            # CSV å¯¼å‡º
            import csv
            import io

            csv_buffer = io.StringIO()
            writer = csv.DictWriter(csv_buffer, fieldnames=item.keys())
            writer.writeheader()
            writer.writerow(item)
            csv_data = csv_buffer.getvalue()

            st.download_button(
                label="ğŸ“¥ CSV æ ¼å¼",
                data=csv_data.encode("utf-8"),
                file_name=f"hot_today_{date}.csv",
                mime="text/csv",
            )

        with col3:
            # æ–‡æœ¬å¯¼å‡º
            current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            text_output = f"""å»å¹´ä»Šæ—¥ - {date}
{"=" * 50}

æ ‡é¢˜: {title}
æ’å: #{rank}
åˆ†ç±»: {category if category else "æœªåˆ†ç±»"}

çƒ­åº¦æ•°æ®:
- çƒ­åº¦å€¼: {heat:.2f}
- é˜…è¯»é‡: {reads:.0f}
- è®¨è®ºé‡: {discussions:.0f}
- åŸåˆ›é‡: {originals:.0f}

ç”Ÿæˆæ—¶é—´: {current_time}
"""
            st.download_button(
                label="ğŸ“¥ æ–‡æœ¬æ ¼å¼",
                data=text_output.encode("utf-8"),
                file_name=f"hot_today_{date}.txt",
                mime="text/plain",
            )

        # ç›¸å…³ä¿¡æ¯
        st.markdown("---")
        st.markdown("### â„¹ï¸  è¯´æ˜")
        st.info("""
        ğŸ’¡ **å¦‚ä½•ä½¿ç”¨è¿™ä¸ªé¡µé¢ï¼š**

        1. **æŸ¥çœ‹å†…å®¹**ï¼šé¡µé¢ä¼šä»å†å²æ•°æ®ä¸­éšæœºé€‰æ‹©ä¸€æ¡ä¸ä»Šå¤©æ—¥æœŸç›¸åŒ/ç›¸è¿‘çš„çƒ­æœ
        2. **åˆ·æ–°æ•°æ®**ï¼šç‚¹å‡»"æ¢ä¸€æ¡"æŒ‰é’®é‡æ–°æŠ½å–ä¸€æ¡
        3. **å¯¼å‡ºæ•°æ®**ï¼šæ”¯æŒ JSONã€CSV å’Œ TXT æ ¼å¼å¯¼å‡º
        4. **æ•°æ®æ¥æº**ï¼šæ¥è‡ªå†å²çƒ­æœæ•°æ®ï¼Œå¯èƒ½æ¥è‡ªå»å¹´æˆ–æ›´æ—©çš„ç›¸åŒæ—¥æœŸ
        """)


# -------- é«˜çº§æ•°æ®æŸ¥è¯¢é¡µé¢ -------- #
@register_page("é«˜çº§æ•°æ®æŸ¥è¯¢")
def page_advanced_query():
    st.title("é«˜çº§æ•°æ®æŸ¥è¯¢ç³»ç»Ÿ")
    st.markdown("""
        æœ¬å·¥å…·æä¾›å¤šæ¡ä»¶æ•°æ®æŸ¥è¯¢åŠŸèƒ½ï¼Œæ”¯æŒæ—¥æœŸèŒƒå›´ã€åˆ†ç±»ç­›é€‰ã€çƒ­åº¦èŒƒå›´ã€æ’åºç­‰å¤šç§æ¡ä»¶ã€‚
        æŸ¥è¯¢ç»“æœå°†è‡ªåŠ¨ä¿å­˜ä¸ºJSONæ–‡ä»¶ï¼Œå¹¶è¿›è¡Œæ•°æ®åˆ†æç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ã€‚
        """)

    # åˆ›å»ºæŸ¥è¯¢å™¨å®ä¾‹
    query = get_data_query()

    # ========== æŸ¥è¯¢æ¡ä»¶è®¾ç½® ==========
    st.markdown("### 1. æŸ¥è¯¢æ¡ä»¶è®¾ç½®")

    # ä½¿ç”¨å¤šåˆ—å¸ƒå±€
    col1, col2 = st.columns(2)

    with col1:
        # æ—¥æœŸèŒƒå›´
        st.markdown("#### ğŸ“… æ—¥æœŸèŒƒå›´")
        date_start = st.text_input(
            "å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)", value="2025-01-01", help="ä¾‹å¦‚: 2025-01-01"
        )
        date_end = st.text_input(
            "ç»“æŸæ—¥æœŸ (YYYY-MM-DD)", value="2025-01-31", help="ä¾‹å¦‚: 2025-01-31"
        )

        # åˆ†ç±»ç­›é€‰
        st.markdown("#### ğŸ·ï¸ åˆ†ç±»ç­›é€‰")
        categories_input = st.text_input(
            "åˆ†ç±» (å¤šä¸ªç”¨é€—å·åˆ†éš”)",
            placeholder="æ˜æ˜Ÿ,ç»¼è‰º,å½±è§†",
            help="ä¾‹å¦‚: æ˜æ˜Ÿ,ç»¼è‰º æˆ–ç•™ç©ºè¡¨ç¤ºä¸è¿‡æ»¤",
        )

        # æ ‡é¢˜å…³é”®è¯
        st.markdown("#### ğŸ” æ ‡é¢˜å…³é”®è¯")
        title_keywords_input = st.text_input(
            "æ ‡é¢˜å…³é”®è¯ (å¤šä¸ªç”¨é€—å·åˆ†éš”)",
            placeholder="æ–°å¹´,æ˜¥æ™š,ç”µå½±",
            help="åŒ…å«ä»»ä¸€å…³é”®è¯çš„æ ‡é¢˜éƒ½ä¼šè¢«é€‰ä¸­",
        )

    with col2:
        # æ’åèŒƒå›´
        st.markdown("#### ğŸ† æ’åèŒƒå›´")
        rank_min = st.number_input("æœ€å°æ’å", min_value=1, max_value=50, value=1)
        rank_max = st.number_input("æœ€å¤§æ’å", min_value=1, max_value=50, value=50)

        # çƒ­åº¦èŒƒå›´
        st.markdown("#### ğŸ”¥ çƒ­åº¦èŒƒå›´")
        heat_min = st.number_input("æœ€å°çƒ­åº¦", min_value=0.0, value=0.0, step=100.0)
        heat_max = st.number_input(
            "æœ€å¤§çƒ­åº¦", min_value=0.0, value=10000000.0, step=1000.0
        )

        # é˜…è¯»é‡èŒƒå›´
        st.markdown("#### ğŸ“– é˜…è¯»é‡èŒƒå›´")
        reads_min = st.number_input("æœ€å°é˜…è¯»é‡", min_value=0, value=0, step=1000)
        reads_max = st.number_input(
            "æœ€å¤§é˜…è¯»é‡", min_value=0, value=50000000, step=1000
        )

    # å…¶ä»–èŒƒå›´è®¾ç½®
    st.markdown("### 2. å…¶ä»–ç­›é€‰æ¡ä»¶")

    col3, col4 = st.columns(2)

    with col3:
        # è®¨è®ºé‡èŒƒå›´
        st.markdown("#### ğŸ’¬ è®¨è®ºé‡èŒƒå›´")
        discussions_min = st.number_input("æœ€å°è®¨è®ºé‡", min_value=0, value=0, step=100)
        discussions_max = st.number_input(
            "æœ€å¤§è®¨è®ºé‡", min_value=0, value=200000, step=100
        )

        # åŸåˆ›é‡èŒƒå›´
        st.markdown("#### âœï¸ åŸåˆ›é‡èŒƒå›´")
        originals_min = st.number_input("æœ€å°åŸåˆ›é‡", min_value=0, value=0, step=100)
        originals_max = st.number_input(
            "æœ€å¤§åŸåˆ›é‡", min_value=0, value=200000, step=100
        )

    with col4:
        # æ’åºæ–¹å¼
        st.markdown("#### ğŸ“Š æ’åºæ–¹å¼")
        sort_options = {
            "çƒ­åº¦é™åº": "heat_desc",
            "çƒ­åº¦å‡åº": "heat_asc",
            "æ’åé™åº": "rank_desc",
            "æ’åå‡åº": "rank_asc",
            "æ—¥æœŸé™åº": "date_desc",
            "æ—¥æœŸå‡åº": "date_asc",
            "é˜…è¯»é‡é™åº": "reads_desc",
            "é˜…è¯»é‡å‡åº": "reads_asc",
            "è®¨è®ºé‡é™åº": "discussions_desc",
            "è®¨è®ºé‡å‡åº": "discussions_asc",
            "åŸåˆ›é‡é™åº": "originals_desc",
            "åŸåˆ›é‡å‡åº": "originals_asc",
            "æ ‡é¢˜å‡åº": "title_asc",
            "æ ‡é¢˜é™åº": "title_desc",
        }
        selected_sort = st.selectbox("é€‰æ‹©æ’åºæ–¹å¼", options=list(sort_options.keys()))
        sort_by = sort_options[selected_sort]

    # ========== æ‰§è¡ŒæŸ¥è¯¢ ==========
    st.markdown("### 3. æ‰§è¡ŒæŸ¥è¯¢ä¸åˆ†æ")

    query_button = st.button(
        "ğŸš€ æ‰§è¡ŒæŸ¥è¯¢å¹¶åˆ†æ", type="primary", use_container_width=True
    )

    if query_button:
        with st.spinner("æ­£åœ¨æ‰§è¡ŒæŸ¥è¯¢ï¼Œè¯·ç¨å€™..."):
            try:
                # å‡†å¤‡æŸ¥è¯¢å‚æ•°
                query_params = {}

                # æ—¥æœŸèŒƒå›´
                if date_start and date_end:
                    query_params["date_range"] = (date_start, date_end)

                # åˆ†ç±»ç­›é€‰
                if categories_input.strip():
                    categories = [
                        c.strip() for c in categories_input.split(",") if c.strip()
                    ]
                    if categories:
                        query_params["categories"] = categories

                # æ’åèŒƒå›´
                if rank_min > 0 or rank_max < 50:
                    query_params["rank_range"] = (rank_min, rank_max)

                # çƒ­åº¦èŒƒå›´
                if heat_min > 0 or heat_max < 10000000.0:
                    query_params["heat_range"] = (heat_min, heat_max)

                # é˜…è¯»é‡èŒƒå›´
                if reads_min > 0 or reads_max < 50000000:
                    query_params["reads_range"] = (reads_min, reads_max)

                # è®¨è®ºé‡èŒƒå›´
                if discussions_min > 0 or discussions_max < 200000:
                    query_params["discussions_range"] = (
                        discussions_min,
                        discussions_max,
                    )

                # åŸåˆ›é‡èŒƒå›´
                if originals_min > 0 or originals_max < 200000:
                    query_params["originals_range"] = (originals_min, originals_max)

                # æ ‡é¢˜å…³é”®è¯
                if title_keywords_input.strip():
                    keywords = [
                        k.strip() for k in title_keywords_input.split(",") if k.strip()
                    ]
                    if keywords:
                        query_params["title_keywords"] = keywords

                # æ’åºæ–¹å¼
                query_params["sort_by"] = sort_by

                # æ‰§è¡ŒæŸ¥è¯¢
                results = query.query(**query_params)

                if not results:
                    st.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ•°æ®")
                    return

                st.success(f"âœ… æŸ¥è¯¢æˆåŠŸï¼æ‰¾åˆ° {len(results)} æ¡ç¬¦åˆæ¡ä»¶çš„æ•°æ®")

                # ä¿å­˜æŸ¥è¯¢ç»“æœåˆ°ä¸´æ—¶æ–‡ä»¶
                import os
                import tempfile
                from datetime import datetime

                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                temp_dir = tempfile.mkdtemp()
                temp_json_path = os.path.join(
                    temp_dir, f"query_results_{timestamp}.json"
                )

                # ä¿å­˜ç»“æœ
                query.save_results(results, temp_json_path)

                # ========== æ˜¾ç¤ºæŸ¥è¯¢ç»“æœè¡¨æ ¼ ==========
                st.markdown("### 4. æŸ¥è¯¢ç»“æœè¡¨æ ¼")

                # è½¬æ¢ä¸ºDataFrameç”¨äºæ˜¾ç¤º
                df_results = pd.DataFrame(results)

                # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
                st.dataframe(df_results, use_container_width=True, height=400)

                # ä¸‹è½½æŒ‰é’®
                col_d1, col_d2 = st.columns(2)
                with col_d1:
                    # ä¸‹è½½JSON
                    with open(temp_json_path, "r", encoding="utf-8") as f:
                        json_data = f.read()
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½JSONæ•°æ®",
                        data=json_data,
                        file_name=f"query_results_{timestamp}.json",
                        mime="application/json",
                    )

                with col_d2:
                    # ä¸‹è½½CSV
                    csv_data = df_results.to_csv(index=False, encoding="utf-8-sig")
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½CSVæ•°æ®",
                        data=csv_data.encode("utf-8"),
                        file_name=f"query_results_{timestamp}.csv",
                        mime="text/csv",
                    )

                # ========== æ•°æ®åˆ†æä¸å¯è§†åŒ– ==========
                st.markdown("### 5. æ•°æ®åˆ†æä¸å¯è§†åŒ–")

                with st.spinner("æ­£åœ¨è¿›è¡Œæ•°æ®åˆ†æï¼Œç”Ÿæˆå¯è§†åŒ–å›¾è¡¨..."):
                    try:
                        # åˆ›å»ºè¾“å‡ºç›®å½•
                        output_dir_name = f"query_analysis_{timestamp}"
                        output_dir = Path("output") / output_dir_name
                        output_dir.mkdir(parents=True, exist_ok=True)

                        # è°ƒç”¨json_analyzeråˆ†ææ•°æ®
                        analysis_result = analyze_data(
                            results, output_dir_name, temp_json_path
                        )

                        st.success("âœ… æ•°æ®åˆ†æå®Œæˆï¼")

                        # æ˜¾ç¤ºç”Ÿæˆçš„å›¾è¡¨
                        chart_files = list(output_dir.glob("*.png"))
                        if chart_files:
                            st.markdown("#### ğŸ“ˆ åˆ†æå›¾è¡¨")

                            # åˆ›å»ºé€‰é¡¹å¡æ˜¾ç¤ºå›¾è¡¨
                            tabs = st.tabs(
                                [f"å›¾è¡¨{i + 1}" for i in range(len(chart_files))]
                            )

                            for tab, chart_file in zip(tabs, chart_files):
                                with tab:
                                    st.image(
                                        str(chart_file),
                                        use_column_width=True,
                                        caption=chart_file.name,
                                    )

                            # æ˜¾ç¤ºåˆ†ææŠ¥å‘Š
                            report_file = output_dir / "analysis_report.txt"
                            if report_file.exists():
                                with st.expander("ğŸ“„ æŸ¥çœ‹åˆ†ææŠ¥å‘Š"):
                                    with open(report_file, "r", encoding="utf-8") as f:
                                        report_content = f.read()
                                    st.text(report_content)

                        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                        st.markdown("#### ğŸ“Š æ•°æ®ç»Ÿè®¡")
                        col_s1, col_s2, col_s3, col_s4 = st.columns(4)

                        with col_s1:
                            st.metric("æ€»è®°å½•æ•°", len(results))

                        with col_s2:
                            if results:
                                avg_heat = sum(r.get("heat", 0) for r in results) / len(
                                    results
                                )
                                st.metric("å¹³å‡çƒ­åº¦", f"{avg_heat:.1f}")

                        with col_s3:
                            if results:
                                unique_categories = set(
                                    r.get("category", "")
                                    for r in results
                                    if r.get("category")
                                )
                                st.metric("åˆ†ç±»æ•°é‡", len(unique_categories))

                        with col_s4:
                            if results and "date" in results[0]:
                                dates = set(
                                    r.get("date", "") for r in results if r.get("date")
                                )
                                st.metric("æ—¥æœŸæ•°é‡", len(dates))

                    except Exception as e:
                        st.error(f"æ•°æ®åˆ†æå¤±è´¥: {str(e)}")
                        import traceback

                        st.error(traceback.format_exc())

                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    os.unlink(temp_json_path)
                    os.rmdir(temp_dir)
                except:
                    pass

            except Exception as e:
                st.error(f"æŸ¥è¯¢å¤±è´¥: {str(e)}")
                import traceback

                st.error(traceback.format_exc())

    # ========== æŸ¥è¯¢ç¤ºä¾‹ ==========
    with st.expander("ğŸ“‹ æŸ¥è¯¢ç¤ºä¾‹", expanded=False):
        st.markdown("""
        **ç¤ºä¾‹1ï¼šæŸ¥è¯¢2025å¹´1æœˆæ‰€æœ‰æ˜æ˜Ÿç±»çƒ­æœ**
        - å¼€å§‹æ—¥æœŸ: 2025-01-01
        - ç»“æŸæ—¥æœŸ: 2025-01-31
        - åˆ†ç±»: æ˜æ˜Ÿ
        - æ’åº: çƒ­åº¦é™åº

        **ç¤ºä¾‹2ï¼šæŸ¥è¯¢çƒ­åº¦å¤§äº10000çš„çƒ­æœ**
        - çƒ­åº¦èŒƒå›´: æœ€å°çƒ­åº¦ 10000
        - æ’åº: çƒ­åº¦é™åº

        **ç¤ºä¾‹3ï¼šæŸ¥è¯¢åŒ…å«"æ–°å¹´"å…³é”®è¯çš„çƒ­æœ**
        - æ ‡é¢˜å…³é”®è¯: æ–°å¹´
        - æ’åº: æ—¥æœŸé™åº
        """)


# -------- ä¸»å…¥å£ -------- #
def main():
    st.sidebar.title("åŠŸèƒ½å¯¼èˆª")
    page_name = st.sidebar.selectbox("é€‰æ‹©é¡µé¢", options=list(PAGES.keys()))

    # æ·»åŠ ä¾§è¾¹æ ä¿¡æ¯
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ“Š é¡¹ç›®ä¿¡æ¯")
    st.sidebar.info("**å¾®åšçƒ­æœæ•°æ®åˆ†æç³»ç»Ÿ**\n\nå®æ—¶è·å–å’Œåˆ†æå¾®åšçƒ­æœè¶‹åŠ¿")

    st.sidebar.markdown("### ğŸ“– ä½¿ç”¨è¯´æ˜")
    with st.sidebar.expander("å®æ—¶çƒ­æœ", expanded=False):
        st.markdown("""
        - è·å–å¾®åšå®æ—¶ Top 50 çƒ­æœ
        - æ”¯æŒç¼“å­˜åŠ é€Ÿ
        - å¯ä¸‹è½½ JSON æ•°æ®
        """)

    with st.sidebar.expander("å•æ—¥çƒ­æœåˆ†æ", expanded=False):
        st.markdown("""
        - é€‰æ‹©æ—¥æœŸåˆ†æå•æ—¥æ•°æ®
        - è°ƒç”¨ json_analyzer æ¨¡å—
        - æ”¯æŒæ•°æ®å¯¼å‡º
        """)

    with st.sidebar.expander("å¹´åº¦å…³é”®è¯ç½‘ç»œ", expanded=False):
        st.markdown("""
        - æŸ¥çœ‹å…³é”®è¯å…±ç°ç½‘ç»œ
        - èŠ‚ç‚¹å’Œè¾¹çš„ç»Ÿè®¡æ•°æ®
        - å¯¼å‡ºæ•°æ®ä¸º CSV
        """)

    with st.sidebar.expander("è¯äº‘å›¾å¯è§†åŒ–", expanded=False):
        st.markdown("""
        - æŸ¥çœ‹å†å²è¯äº‘å›¾
        - æŒ‰å…³é”®è¯/ç±»å‹åˆ†æ
        - æ”¯æŒæœˆåº¦/å­£åº¦/å¹´åº¦
        """)

    with st.sidebar.expander("æ•°æ®å¤„ç†", expanded=False):
        st.markdown("""
        - æ•°æ®æ¸…æ´—ä¸è½¬æ¢
        - æ‰¹é‡å¯¼å‡ºå·¥å…·
        - è‡ªå®šä¹‰åˆ†æ
        """)

    with st.sidebar.expander("å»å¹´ä»Šæ—¥", expanded=False):
        st.markdown("""
        - ä»å†å²æ•°æ®éšæœºæŸ¥æ‰¾
        - ç›¸åŒæ—¥æœŸçš„å¾€å¹´çƒ­æœ
        - æ”¯æŒå¤šæ ¼å¼å¯¼å‡º
        """)

    st.sidebar.markdown("---")
    st.sidebar.markdown("### âš™ï¸ ç³»ç»ŸçŠ¶æ€")
    import os
    from pathlib import Path

    # ç»Ÿè®¡æ•°æ®
    data_dir = Path("data")
    output_dir = Path("output/word_clouds")
    network_dir = Path("output/word_networks")

    if data_dir.exists():
        json_files = list(data_dir.glob("**/*.json"))
        st.sidebar.success(f"âœ“ å·²å­˜å‚¨ {len(json_files)} ä¸ªæ•°æ®æ–‡ä»¶")
    else:
        st.sidebar.warning("âš  æ•°æ®ç›®å½•ä¸å­˜åœ¨")

    if output_dir.exists():
        img_files = list(output_dir.glob("**/*.png"))
        st.sidebar.success(f"âœ“ å·²ç”Ÿæˆ {len(img_files)} å¼ è¯äº‘å›¾")
    else:
        st.sidebar.warning("âš  è¯äº‘å›¾ç›®å½•ä¸å­˜åœ¨")

    if network_dir.exists():
        network_files = list(network_dir.glob("**/*.json"))
        st.sidebar.success(f"âœ“ å·²ç”Ÿæˆ {len(network_files) // 2} ä¸ªç½‘ç»œå›¾")
    else:
        st.sidebar.warning("âš  ç½‘ç»œå›¾ç›®å½•ä¸å­˜åœ¨")

    PAGES[page_name]()


if __name__ == "__main__":
    main()
